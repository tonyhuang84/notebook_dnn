{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tony/dnn/anaconda2/envs/myjupyter/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# IMPORTING IMPORTANT LIBRARIES\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "import preprocessing \n",
    "\n",
    "# FOR REPRODUCIBILITY\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_OHLC.len:1248 test_OHLC.len:416\n",
      "train_OHLC:array([[0.01530745],\n",
      "       [0.0196717 ],\n",
      "       [0.02058364],\n",
      "       ...,\n",
      "       [0.57970731],\n",
      "       [0.57634184],\n",
      "       [0.57117422]])\n",
      "trainX_ts(len:1246):array([[0.01530745],\n",
      "       [0.0196717 ],\n",
      "       [0.02058364],\n",
      "       ...,\n",
      "       [0.61776967],\n",
      "       [0.60029095],\n",
      "       [0.57970731]])\n",
      "trainY(len:1246):array([0.0196717 , 0.02058364, 0.02347143, ..., 0.60029095, 0.57970731,\n",
      "       0.57634184])\n",
      "trainX.reshape:array([[[0.01530745]],\n",
      "\n",
      "       [[0.0196717 ]],\n",
      "\n",
      "       [[0.02058364]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.61776967]],\n",
      "\n",
      "       [[0.60029095]],\n",
      "\n",
      "       [[0.57970731]]])\n"
     ]
    }
   ],
   "source": [
    "# IMPORTING DATASET \n",
    "dataset = pd.read_csv('apple_share_price.csv', usecols=[1,2,3,4])\n",
    "dataset = dataset.reindex(index = dataset.index[::-1])\n",
    "#print dataset\n",
    "\n",
    "# CREATING OWN INDEX FOR FLEXIBILITY\n",
    "#obs = np.arange(1, len(dataset) + 1, 1)  # 建立 [1 ... 1664] index 作為繪圖 x 軸\n",
    "#print obs\n",
    "\n",
    "# TAKING DIFFERENT INDICATORS FOR PREDICTION\n",
    "OHLC_avg_org = dataset.mean(axis = 1)\n",
    "HLC_avg = dataset[['High', 'Low', 'Close']].mean(axis = 1)\n",
    "close_val = dataset[['Close']]\n",
    "\n",
    "# PREPARATION OF TIME SERIES DATASE\n",
    "OHLC_avg_rs = np.reshape(OHLC_avg_org.values, (len(OHLC_avg_org),1)) # 1664; 將矩陣從 1*1664 轉置成 1664*1\n",
    "#print(\"OHLC_avg_rs: %r\" % (OHLC_avg_rs))\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "OHLC_avg = scaler.fit_transform(OHLC_avg_rs)  # normalize 到 [0, 1]\n",
    "#print(\"OHLC_avg.scaler: %r\" % (OHLC_avg))\n",
    "\n",
    "# TRAIN-TEST SPLIT\n",
    "train_OHLC = int(len(OHLC_avg) * 0.75)\n",
    "test_OHLC = len(OHLC_avg) - train_OHLC\n",
    "train_OHLC, test_OHLC = OHLC_avg[0:train_OHLC,:], OHLC_avg[train_OHLC:len(OHLC_avg),:]\n",
    "print(\"train_OHLC.len:%d test_OHLC.len:%d\" % (len(train_OHLC), len(test_OHLC)))\n",
    "print(\"train_OHLC:%r\" % (train_OHLC))\n",
    "\n",
    "# TIME-SERIES DATASET (FOR TIME T, VALUES FOR TIME T+1)\n",
    "if (1): #TonyH\n",
    "    trainX_ts, trainY = preprocessing.new_dataset(train_OHLC, 0)\n",
    "    testX_ts, testY = preprocessing.new_dataset(test_OHLC, 0)\n",
    "else:\n",
    "    trainX_ts, trainY = preprocessing.new_dataset(train_OHLC, 1)\n",
    "    testX_ts, testY = preprocessing.new_dataset(test_OHLC, 1)\n",
    "print(\"trainX_ts(len:%d):%r\" % (len(trainX_ts), trainX_ts))\n",
    "print(\"trainY(len:%d):%r\" % (len(trainY), trainY))\n",
    "\n",
    "# RESHAPING TRAIN AND TEST DATA\n",
    "trainX = np.reshape(trainX_ts, (trainX_ts.shape[0], 1, trainX_ts.shape[1]))\n",
    "testX = np.reshape(testX_ts, (testX_ts.shape[0], 1, testX_ts.shape[1]))\n",
    "step_size = 1\n",
    "print(\"trainX.reshape:%r\" % (trainX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_OHLC.len:1248 test_OHLC.len:416\n",
      "trainX.reshape:array([[[0.01530745]],\n",
      "\n",
      "       [[0.0196717 ]],\n",
      "\n",
      "       [[0.02058364]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.61776967]],\n",
      "\n",
      "       [[0.60029095]],\n",
      "\n",
      "       [[0.57970731]]])\n",
      "Epoch 1/5\n",
      " - 6s - loss: 0.0046\n",
      "Epoch 2/5\n",
      " - 6s - loss: 3.1900e-04\n",
      "Epoch 3/5\n",
      " - 5s - loss: 2.7418e-04\n",
      "Epoch 4/5\n",
      " - 5s - loss: 2.3755e-04\n",
      "Epoch 5/5\n",
      " - 5s - loss: 2.1279e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe47ef26450>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM MODEL\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(1, step_size), return_sequences = True))\n",
    "model.add(LSTM(16))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "# MODEL COMPILING\n",
    "model.compile(loss='mean_squared_error', optimizer='adagrad') # Try SGD, adam, adagrad and compare!!!\n",
    "\n",
    "# Training\n",
    "model.fit(trainX, trainY, epochs=5, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "# DE-NORMALIZING FOR PLOTTING\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "\n",
    "# TRAINING RMSE\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train RMSE: %.2f' % (trainScore))\n",
    "\n",
    "# TEST RMSE\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test RMSE: %.2f' % (testScore))\n",
    "#print(\"testY[0]:%r\" % (testY[0]))\n",
    "#print(\"testPredict[:,0]:%r\" % (testPredict[:,0]))\n",
    "\n",
    "# CREATING SIMILAR DATASET TO PLOT TRAINING PREDICTIONS\n",
    "trainPredictPlot = np.empty_like(OHLC_avg)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[step_size:len(trainPredict)+step_size, :] = trainPredict\n",
    "\n",
    "# CREATING SIMILAR DATASSET TO PLOT TEST PREDICTIONS\n",
    "testPredictPlot = np.empty_like(OHLC_avg)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(step_size*2)+1:len(OHLC_avg)-1, :] = testPredict\n",
    "\n",
    "# DE-NORMALIZING MAIN DATASET \n",
    "OHLC_avg = scaler.inverse_transform(OHLC_avg)\n",
    "\n",
    "# PLOT OF MAIN OHLC VALUES, TRAIN PREDICTIONS AND TEST PREDICTIONS\n",
    "plt.plot(OHLC_avg, 'g', label = 'original dataset')\n",
    "plt.plot(trainPredictPlot, 'r', label = 'training set')\n",
    "plt.plot(testPredictPlot, 'b', label = 'predicted stock price/test set')\n",
    "#plt.legend(loc = 'upper right')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel('Time in Days')\n",
    "plt.ylabel('OHLC Value of Apple Stocks')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICT FUTURE VALUES\n",
    "last_val = testPredict[-1]\n",
    "print(\"last_val:%r\" % (last_val))\n",
    "last_val_scaled = last_val/last_val\n",
    "print(\"last_val_scaled:%r\" % (last_val_scaled))\n",
    "next_val = model.predict(np.reshape(last_val_scaled, (1,1,1)))\n",
    "print(\"next_val:%r\" % (next_val))\n",
    "print \"Last Day Value:\", np.asscalar(last_val)\n",
    "print \"Next Day Value:\", np.asscalar(last_val*next_val)\n",
    "# print np.append(last_val, next_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
