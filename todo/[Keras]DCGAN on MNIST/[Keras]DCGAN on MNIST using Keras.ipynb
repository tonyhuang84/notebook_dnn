{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source:  \n",
    "https://github.com/roatienza/Deep-Learning-Experiments/blob/master/Experiments/Tensorflow/GAN/dcgan_mnist.py  \n",
    "https://zhuanlan.zhihu.com/p/22386494 (介紹1)  \n",
    "https://zhuanlan.zhihu.com/p/22389906 (介紹2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tony/dnn/anaconda2/envs/myjupyter/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/train-images-idx3-ubyte.gz\n",
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 256)         819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 8193      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 4,311,553\n",
      "Trainable params: 4,311,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 12544)             1266944   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 12544)             50176     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 128)       819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 28, 28, 1)         801       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 2,394,241\n",
      "Trainable params: 2,368,705\n",
      "Non-trainable params: 25,536\n",
      "_________________________________________________________________\n",
      "0: [D loss: 0.692462, acc: 0.535156]  [A loss: 1.728962, acc: 0.000000]\n",
      "1: [D loss: 0.645839, acc: 0.675781]  [A loss: 4.418802, acc: 0.000000]\n",
      "2: [D loss: 0.586071, acc: 0.617188]  [A loss: 1.194311, acc: 0.000000]\n",
      "3: [D loss: 0.848003, acc: 0.500000]  [A loss: 8.595425, acc: 0.000000]\n",
      "4: [D loss: 0.443428, acc: 0.697266]  [A loss: 0.854310, acc: 0.207031]\n",
      "5: [D loss: 1.075523, acc: 0.500000]  [A loss: 8.319912, acc: 0.000000]\n",
      "6: [D loss: 0.435773, acc: 0.736328]  [A loss: 1.233149, acc: 0.023438]\n",
      "7: [D loss: 0.689073, acc: 0.546875]  [A loss: 6.579512, acc: 0.000000]\n",
      "8: [D loss: 0.361796, acc: 0.882812]  [A loss: 1.955769, acc: 0.000000]\n",
      "9: [D loss: 0.699537, acc: 0.583984]  [A loss: 9.514639, acc: 0.000000]\n",
      "10: [D loss: 0.493527, acc: 0.746094]  [A loss: 0.978452, acc: 0.250000]\n",
      "11: [D loss: 1.089865, acc: 0.505859]  [A loss: 11.382610, acc: 0.000000]\n",
      "12: [D loss: 0.682624, acc: 0.646484]  [A loss: 0.945929, acc: 0.253906]\n",
      "13: [D loss: 1.273221, acc: 0.480469]  [A loss: 10.063911, acc: 0.000000]\n",
      "14: [D loss: 0.680802, acc: 0.675781]  [A loss: 1.063469, acc: 0.210938]\n",
      "15: [D loss: 1.190326, acc: 0.494141]  [A loss: 8.669041, acc: 0.000000]\n",
      "16: [D loss: 0.643763, acc: 0.693359]  [A loss: 1.035422, acc: 0.238281]\n",
      "17: [D loss: 1.207953, acc: 0.472656]  [A loss: 8.022726, acc: 0.000000]\n",
      "18: [D loss: 0.598085, acc: 0.693359]  [A loss: 0.993245, acc: 0.292969]\n",
      "19: [D loss: 1.171970, acc: 0.486328]  [A loss: 8.182528, acc: 0.000000]\n",
      "20: [D loss: 0.617914, acc: 0.681641]  [A loss: 0.972177, acc: 0.261719]\n",
      "21: [D loss: 1.235847, acc: 0.466797]  [A loss: 7.655742, acc: 0.000000]\n",
      "22: [D loss: 0.621613, acc: 0.671875]  [A loss: 0.923331, acc: 0.316406]\n",
      "23: [D loss: 1.195720, acc: 0.488281]  [A loss: 7.227969, acc: 0.000000]\n",
      "24: [D loss: 0.607509, acc: 0.701172]  [A loss: 1.007857, acc: 0.210938]\n",
      "25: [D loss: 1.170387, acc: 0.490234]  [A loss: 6.958437, acc: 0.000000]\n",
      "26: [D loss: 0.571934, acc: 0.707031]  [A loss: 0.901991, acc: 0.281250]\n",
      "27: [D loss: 1.190286, acc: 0.492188]  [A loss: 7.638419, acc: 0.000000]\n",
      "28: [D loss: 0.663073, acc: 0.673828]  [A loss: 0.637821, acc: 0.597656]\n",
      "29: [D loss: 1.299038, acc: 0.488281]  [A loss: 6.973828, acc: 0.000000]\n",
      "30: [D loss: 0.591489, acc: 0.703125]  [A loss: 0.800953, acc: 0.480469]\n",
      "31: [D loss: 1.161993, acc: 0.494141]  [A loss: 6.381623, acc: 0.000000]\n",
      "32: [D loss: 0.556119, acc: 0.730469]  [A loss: 0.882080, acc: 0.355469]\n",
      "33: [D loss: 1.128803, acc: 0.498047]  [A loss: 6.833334, acc: 0.000000]\n",
      "34: [D loss: 0.573225, acc: 0.697266]  [A loss: 0.672421, acc: 0.570312]\n",
      "35: [D loss: 1.220163, acc: 0.500000]  [A loss: 6.455287, acc: 0.000000]\n",
      "36: [D loss: 0.554081, acc: 0.703125]  [A loss: 0.707594, acc: 0.507812]\n",
      "37: [D loss: 1.117818, acc: 0.500000]  [A loss: 5.949339, acc: 0.000000]\n",
      "38: [D loss: 0.469431, acc: 0.798828]  [A loss: 0.848091, acc: 0.351562]\n",
      "39: [D loss: 1.043928, acc: 0.503906]  [A loss: 6.482644, acc: 0.000000]\n",
      "40: [D loss: 0.513491, acc: 0.744141]  [A loss: 0.620484, acc: 0.664062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41: [D loss: 1.120831, acc: 0.501953]  [A loss: 6.569053, acc: 0.000000]\n",
      "42: [D loss: 0.474764, acc: 0.779297]  [A loss: 0.685098, acc: 0.570312]\n",
      "43: [D loss: 1.142588, acc: 0.500000]  [A loss: 6.378450, acc: 0.000000]\n",
      "44: [D loss: 0.460514, acc: 0.789062]  [A loss: 0.641844, acc: 0.621094]\n",
      "45: [D loss: 1.061949, acc: 0.501953]  [A loss: 5.958043, acc: 0.000000]\n",
      "46: [D loss: 0.425565, acc: 0.824219]  [A loss: 0.820232, acc: 0.429688]\n",
      "47: [D loss: 1.011864, acc: 0.501953]  [A loss: 6.051521, acc: 0.000000]\n",
      "48: [D loss: 0.405273, acc: 0.837891]  [A loss: 0.727746, acc: 0.519531]\n",
      "49: [D loss: 1.096560, acc: 0.500000]  [A loss: 6.932978, acc: 0.000000]\n",
      "50: [D loss: 0.494640, acc: 0.744141]  [A loss: 0.440544, acc: 0.859375]\n",
      "51: [D loss: 1.110068, acc: 0.500000]  [A loss: 5.813478, acc: 0.000000]\n",
      "52: [D loss: 0.376688, acc: 0.892578]  [A loss: 0.911562, acc: 0.324219]\n",
      "53: [D loss: 0.960966, acc: 0.503906]  [A loss: 6.330828, acc: 0.000000]\n",
      "54: [D loss: 0.391854, acc: 0.867188]  [A loss: 0.742727, acc: 0.511719]\n",
      "55: [D loss: 1.061199, acc: 0.500000]  [A loss: 6.946042, acc: 0.000000]\n",
      "56: [D loss: 0.444104, acc: 0.814453]  [A loss: 0.408741, acc: 0.910156]\n",
      "57: [D loss: 1.090653, acc: 0.500000]  [A loss: 6.021115, acc: 0.000000]\n",
      "58: [D loss: 0.399647, acc: 0.863281]  [A loss: 0.561667, acc: 0.722656]\n",
      "59: [D loss: 1.049304, acc: 0.501953]  [A loss: 6.540499, acc: 0.000000]\n",
      "60: [D loss: 0.439891, acc: 0.814453]  [A loss: 0.304717, acc: 0.972656]\n",
      "61: [D loss: 1.134867, acc: 0.500000]  [A loss: 5.919036, acc: 0.000000]\n",
      "62: [D loss: 0.425297, acc: 0.832031]  [A loss: 0.403011, acc: 0.910156]\n",
      "63: [D loss: 1.063774, acc: 0.500000]  [A loss: 5.662895, acc: 0.000000]\n",
      "64: [D loss: 0.399372, acc: 0.875000]  [A loss: 0.494924, acc: 0.808594]\n",
      "65: [D loss: 0.995098, acc: 0.507812]  [A loss: 5.581556, acc: 0.000000]\n",
      "66: [D loss: 0.391268, acc: 0.882812]  [A loss: 0.588412, acc: 0.703125]\n",
      "67: [D loss: 0.962505, acc: 0.505859]  [A loss: 5.224788, acc: 0.000000]\n",
      "68: [D loss: 0.443290, acc: 0.867188]  [A loss: 0.396531, acc: 0.898438]\n",
      "69: [D loss: 1.007753, acc: 0.500000]  [A loss: 4.345806, acc: 0.000000]\n",
      "70: [D loss: 0.370453, acc: 0.931641]  [A loss: 1.024986, acc: 0.175781]\n",
      "71: [D loss: 0.855164, acc: 0.511719]  [A loss: 5.368564, acc: 0.000000]\n",
      "72: [D loss: 0.433806, acc: 0.855469]  [A loss: 0.329940, acc: 0.984375]\n",
      "73: [D loss: 1.032210, acc: 0.500000]  [A loss: 3.727363, acc: 0.000000]\n",
      "74: [D loss: 0.395781, acc: 0.914062]  [A loss: 0.902497, acc: 0.292969]\n",
      "75: [D loss: 0.816968, acc: 0.511719]  [A loss: 5.333808, acc: 0.000000]\n",
      "76: [D loss: 0.497694, acc: 0.839844]  [A loss: 0.200928, acc: 1.000000]\n",
      "77: [D loss: 1.154459, acc: 0.500000]  [A loss: 2.958209, acc: 0.000000]\n",
      "78: [D loss: 0.402848, acc: 0.822266]  [A loss: 1.607116, acc: 0.019531]\n",
      "79: [D loss: 0.690922, acc: 0.533203]  [A loss: 4.866680, acc: 0.000000]\n",
      "80: [D loss: 0.473103, acc: 0.855469]  [A loss: 0.221983, acc: 1.000000]\n",
      "81: [D loss: 1.148551, acc: 0.500000]  [A loss: 3.055001, acc: 0.000000]\n",
      "82: [D loss: 0.396664, acc: 0.869141]  [A loss: 1.140777, acc: 0.109375]\n",
      "83: [D loss: 0.761075, acc: 0.513672]  [A loss: 4.932654, acc: 0.000000]\n",
      "84: [D loss: 0.554107, acc: 0.826172]  [A loss: 0.122352, acc: 1.000000]\n",
      "85: [D loss: 1.260426, acc: 0.500000]  [A loss: 2.094323, acc: 0.000000]\n",
      "86: [D loss: 0.468219, acc: 0.667969]  [A loss: 2.477613, acc: 0.000000]\n",
      "87: [D loss: 0.480510, acc: 0.675781]  [A loss: 2.791313, acc: 0.000000]\n",
      "88: [D loss: 0.485038, acc: 0.666016]  [A loss: 2.929403, acc: 0.000000]\n",
      "89: [D loss: 0.464804, acc: 0.695312]  [A loss: 2.807487, acc: 0.000000]\n",
      "90: [D loss: 0.525551, acc: 0.642578]  [A loss: 3.749694, acc: 0.000000]\n",
      "91: [D loss: 0.420543, acc: 0.828125]  [A loss: 0.883409, acc: 0.289062]\n",
      "92: [D loss: 0.976017, acc: 0.501953]  [A loss: 8.067833, acc: 0.000000]\n",
      "93: [D loss: 1.471557, acc: 0.523438]  [A loss: 0.011042, acc: 1.000000]\n",
      "94: [D loss: 1.932132, acc: 0.500000]  [A loss: 0.115571, acc: 1.000000]\n",
      "95: [D loss: 1.098333, acc: 0.500000]  [A loss: 0.529121, acc: 0.828125]\n",
      "96: [D loss: 0.704324, acc: 0.503906]  [A loss: 1.392995, acc: 0.007812]\n",
      "97: [D loss: 0.530961, acc: 0.570312]  [A loss: 1.708604, acc: 0.000000]\n",
      "98: [D loss: 0.533185, acc: 0.611328]  [A loss: 2.016715, acc: 0.003906]\n",
      "99: [D loss: 0.546202, acc: 0.591797]  [A loss: 2.521711, acc: 0.000000]\n",
      "100: [D loss: 0.514073, acc: 0.656250]  [A loss: 2.024753, acc: 0.000000]\n",
      "101: [D loss: 0.607149, acc: 0.564453]  [A loss: 3.341335, acc: 0.000000]\n",
      "102: [D loss: 0.437340, acc: 0.791016]  [A loss: 1.453940, acc: 0.027344]\n",
      "103: [D loss: 0.750387, acc: 0.517578]  [A loss: 4.875099, acc: 0.000000]\n",
      "104: [D loss: 0.643500, acc: 0.744141]  [A loss: 0.043288, acc: 1.000000]\n",
      "105: [D loss: 1.577608, acc: 0.500000]  [A loss: 1.220353, acc: 0.050781]\n",
      "106: [D loss: 0.581311, acc: 0.552734]  [A loss: 2.355249, acc: 0.000000]\n",
      "107: [D loss: 0.499563, acc: 0.677734]  [A loss: 1.731664, acc: 0.007812]\n",
      "108: [D loss: 0.638551, acc: 0.541016]  [A loss: 3.640811, acc: 0.000000]\n",
      "109: [D loss: 0.456183, acc: 0.845703]  [A loss: 0.508865, acc: 0.808594]\n",
      "110: [D loss: 0.916740, acc: 0.501953]  [A loss: 4.730315, acc: 0.000000]\n",
      "111: [D loss: 0.655012, acc: 0.716797]  [A loss: 0.035479, acc: 1.000000]\n",
      "112: [D loss: 1.650192, acc: 0.500000]  [A loss: 0.881423, acc: 0.281250]\n",
      "113: [D loss: 0.681482, acc: 0.513672]  [A loss: 2.532315, acc: 0.000000]\n",
      "114: [D loss: 0.456646, acc: 0.755859]  [A loss: 1.255656, acc: 0.066406]\n",
      "115: [D loss: 0.711336, acc: 0.511719]  [A loss: 4.127113, acc: 0.000000]\n",
      "116: [D loss: 0.467129, acc: 0.830078]  [A loss: 0.319332, acc: 0.988281]\n",
      "117: [D loss: 1.029698, acc: 0.500000]  [A loss: 4.150237, acc: 0.000000]\n",
      "118: [D loss: 0.497163, acc: 0.830078]  [A loss: 0.154620, acc: 1.000000]\n",
      "119: [D loss: 1.182433, acc: 0.500000]  [A loss: 2.610913, acc: 0.000000]\n",
      "120: [D loss: 0.430479, acc: 0.812500]  [A loss: 1.156992, acc: 0.105469]\n",
      "121: [D loss: 0.756969, acc: 0.517578]  [A loss: 4.614449, acc: 0.000000]\n",
      "122: [D loss: 0.531077, acc: 0.810547]  [A loss: 0.121130, acc: 1.000000]\n",
      "123: [D loss: 1.323571, acc: 0.500000]  [A loss: 2.780421, acc: 0.000000]\n",
      "124: [D loss: 0.419511, acc: 0.796875]  [A loss: 1.345411, acc: 0.062500]\n",
      "125: [D loss: 0.766704, acc: 0.519531]  [A loss: 5.091359, acc: 0.000000]\n",
      "126: [D loss: 0.524899, acc: 0.796875]  [A loss: 0.082006, acc: 1.000000]\n",
      "127: [D loss: 1.486202, acc: 0.500000]  [A loss: 2.269536, acc: 0.000000]\n",
      "128: [D loss: 0.477041, acc: 0.714844]  [A loss: 1.894642, acc: 0.007812]\n",
      "129: [D loss: 0.671074, acc: 0.541016]  [A loss: 4.945112, acc: 0.000000]\n",
      "130: [D loss: 0.506945, acc: 0.806641]  [A loss: 0.109427, acc: 1.000000]\n",
      "131: [D loss: 1.427992, acc: 0.500000]  [A loss: 3.347901, acc: 0.000000]\n",
      "132: [D loss: 0.427316, acc: 0.843750]  [A loss: 0.568220, acc: 0.742188]\n",
      "133: [D loss: 1.061853, acc: 0.500000]  [A loss: 5.570356, acc: 0.000000]\n",
      "134: [D loss: 0.665830, acc: 0.724609]  [A loss: 0.038963, acc: 1.000000]\n",
      "135: [D loss: 1.715061, acc: 0.500000]  [A loss: 1.007377, acc: 0.171875]\n",
      "136: [D loss: 0.702469, acc: 0.521484]  [A loss: 3.018985, acc: 0.000000]\n",
      "137: [D loss: 0.442836, acc: 0.791016]  [A loss: 0.973300, acc: 0.234375]\n",
      "138: [D loss: 0.881936, acc: 0.505859]  [A loss: 5.018078, acc: 0.000000]\n",
      "139: [D loss: 0.538546, acc: 0.783203]  [A loss: 0.084079, acc: 1.000000]\n",
      "140: [D loss: 1.518801, acc: 0.500000]  [A loss: 2.581238, acc: 0.000000]\n",
      "141: [D loss: 0.479632, acc: 0.703125]  [A loss: 2.070846, acc: 0.000000]\n",
      "142: [D loss: 0.668471, acc: 0.560547]  [A loss: 4.340415, acc: 0.000000]\n",
      "143: [D loss: 0.426666, acc: 0.830078]  [A loss: 0.470627, acc: 0.828125]\n",
      "144: [D loss: 1.019251, acc: 0.503906]  [A loss: 5.716165, acc: 0.000000]\n",
      "145: [D loss: 0.638478, acc: 0.722656]  [A loss: 0.022903, acc: 1.000000]\n",
      "146: [D loss: 1.963854, acc: 0.500000]  [A loss: 1.092964, acc: 0.187500]\n",
      "147: [D loss: 0.758448, acc: 0.523438]  [A loss: 3.768757, acc: 0.000000]\n",
      "148: [D loss: 0.465284, acc: 0.796875]  [A loss: 0.596881, acc: 0.691406]\n",
      "149: [D loss: 0.982476, acc: 0.505859]  [A loss: 5.077392, acc: 0.000000]\n",
      "150: [D loss: 0.542709, acc: 0.785156]  [A loss: 0.063899, acc: 1.000000]\n",
      "151: [D loss: 1.510064, acc: 0.500000]  [A loss: 2.275419, acc: 0.000000]\n",
      "152: [D loss: 0.552904, acc: 0.611328]  [A loss: 3.028099, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153: [D loss: 0.524962, acc: 0.673828]  [A loss: 2.289649, acc: 0.003906]\n",
      "154: [D loss: 0.818959, acc: 0.509766]  [A loss: 6.428046, acc: 0.000000]\n",
      "155: [D loss: 0.740503, acc: 0.683594]  [A loss: 0.010168, acc: 1.000000]\n",
      "156: [D loss: 2.211154, acc: 0.500000]  [A loss: 0.883324, acc: 0.382812]\n",
      "157: [D loss: 0.951178, acc: 0.513672]  [A loss: 4.422016, acc: 0.000000]\n",
      "158: [D loss: 0.507112, acc: 0.779297]  [A loss: 0.239832, acc: 0.984375]\n",
      "159: [D loss: 1.291469, acc: 0.500000]  [A loss: 4.644156, acc: 0.000000]\n",
      "160: [D loss: 0.551421, acc: 0.755859]  [A loss: 0.129374, acc: 0.996094]\n",
      "161: [D loss: 1.368887, acc: 0.500000]  [A loss: 3.572902, acc: 0.000000]\n",
      "162: [D loss: 0.504605, acc: 0.734375]  [A loss: 0.878125, acc: 0.402344]\n",
      "163: [D loss: 1.239998, acc: 0.500000]  [A loss: 7.240736, acc: 0.000000]\n",
      "164: [D loss: 0.970139, acc: 0.617188]  [A loss: 0.007669, acc: 1.000000]\n",
      "165: [D loss: 2.294699, acc: 0.500000]  [A loss: 0.499786, acc: 0.804688]\n",
      "166: [D loss: 1.023519, acc: 0.503906]  [A loss: 2.967864, acc: 0.000000]\n",
      "167: [D loss: 0.592536, acc: 0.632812]  [A loss: 1.990920, acc: 0.019531]\n",
      "168: [D loss: 0.949774, acc: 0.521484]  [A loss: 5.369554, acc: 0.000000]\n",
      "169: [D loss: 0.627698, acc: 0.703125]  [A loss: 0.080861, acc: 1.000000]\n",
      "170: [D loss: 1.652265, acc: 0.500000]  [A loss: 3.827793, acc: 0.000000]\n",
      "171: [D loss: 0.574997, acc: 0.673828]  [A loss: 0.612399, acc: 0.628906]\n",
      "172: [D loss: 1.194792, acc: 0.498047]  [A loss: 5.926216, acc: 0.000000]\n",
      "173: [D loss: 0.758595, acc: 0.656250]  [A loss: 0.029821, acc: 1.000000]\n",
      "174: [D loss: 1.899623, acc: 0.500000]  [A loss: 1.617111, acc: 0.042969]\n",
      "175: [D loss: 0.879768, acc: 0.523438]  [A loss: 3.718267, acc: 0.000000]\n",
      "176: [D loss: 0.570907, acc: 0.685547]  [A loss: 0.894082, acc: 0.402344]\n",
      "177: [D loss: 1.172222, acc: 0.503906]  [A loss: 6.293337, acc: 0.000000]\n",
      "178: [D loss: 0.870347, acc: 0.603516]  [A loss: 0.021450, acc: 1.000000]\n",
      "179: [D loss: 2.171280, acc: 0.500000]  [A loss: 1.686390, acc: 0.039062]\n",
      "180: [D loss: 0.826483, acc: 0.548828]  [A loss: 3.498477, acc: 0.000000]\n",
      "181: [D loss: 0.629651, acc: 0.626953]  [A loss: 1.473983, acc: 0.082031]\n",
      "182: [D loss: 1.215955, acc: 0.507812]  [A loss: 6.537493, acc: 0.000000]\n",
      "183: [D loss: 0.886397, acc: 0.609375]  [A loss: 0.020292, acc: 1.000000]\n",
      "184: [D loss: 2.181695, acc: 0.500000]  [A loss: 1.586878, acc: 0.082031]\n",
      "185: [D loss: 0.852012, acc: 0.517578]  [A loss: 3.120959, acc: 0.000000]\n",
      "186: [D loss: 0.629093, acc: 0.617188]  [A loss: 1.541115, acc: 0.082031]\n",
      "187: [D loss: 1.059099, acc: 0.507812]  [A loss: 5.704834, acc: 0.000000]\n",
      "188: [D loss: 0.824550, acc: 0.578125]  [A loss: 0.030484, acc: 1.000000]\n",
      "189: [D loss: 1.971503, acc: 0.500000]  [A loss: 2.619015, acc: 0.000000]\n",
      "190: [D loss: 0.742504, acc: 0.578125]  [A loss: 2.685653, acc: 0.003906]\n",
      "191: [D loss: 0.774805, acc: 0.529297]  [A loss: 2.943432, acc: 0.000000]\n",
      "192: [D loss: 0.779257, acc: 0.544922]  [A loss: 2.618524, acc: 0.011719]\n",
      "193: [D loss: 0.897540, acc: 0.542969]  [A loss: 4.708964, acc: 0.000000]\n",
      "194: [D loss: 0.802042, acc: 0.556641]  [A loss: 0.079895, acc: 1.000000]\n",
      "195: [D loss: 1.656050, acc: 0.500000]  [A loss: 5.147537, acc: 0.000000]\n",
      "196: [D loss: 0.814389, acc: 0.587891]  [A loss: 0.040750, acc: 1.000000]\n",
      "197: [D loss: 1.727094, acc: 0.500000]  [A loss: 2.078619, acc: 0.003906]\n",
      "198: [D loss: 0.699126, acc: 0.576172]  [A loss: 1.967911, acc: 0.039062]\n",
      "199: [D loss: 0.858019, acc: 0.521484]  [A loss: 4.256085, acc: 0.000000]\n",
      "200: [D loss: 0.689757, acc: 0.623047]  [A loss: 0.198436, acc: 0.976562]\n",
      "201: [D loss: 1.472645, acc: 0.503906]  [A loss: 5.753168, acc: 0.000000]\n",
      "202: [D loss: 0.922326, acc: 0.591797]  [A loss: 0.014315, acc: 1.000000]\n",
      "203: [D loss: 2.324883, acc: 0.500000]  [A loss: 1.261284, acc: 0.167969]\n",
      "204: [D loss: 0.929792, acc: 0.511719]  [A loss: 3.643525, acc: 0.000000]\n",
      "205: [D loss: 0.681545, acc: 0.603516]  [A loss: 0.698379, acc: 0.550781]\n",
      "206: [D loss: 1.289958, acc: 0.494141]  [A loss: 5.650483, acc: 0.000000]\n",
      "207: [D loss: 0.905741, acc: 0.574219]  [A loss: 0.017077, acc: 1.000000]\n",
      "208: [D loss: 2.276228, acc: 0.500000]  [A loss: 1.447816, acc: 0.109375]\n",
      "209: [D loss: 0.846627, acc: 0.529297]  [A loss: 2.985969, acc: 0.000000]\n",
      "210: [D loss: 0.758072, acc: 0.558594]  [A loss: 1.962209, acc: 0.035156]\n",
      "211: [D loss: 1.079318, acc: 0.505859]  [A loss: 5.528694, acc: 0.000000]\n",
      "212: [D loss: 0.786398, acc: 0.597656]  [A loss: 0.078509, acc: 1.000000]\n",
      "213: [D loss: 1.713887, acc: 0.500000]  [A loss: 3.665022, acc: 0.000000]\n",
      "214: [D loss: 0.723085, acc: 0.609375]  [A loss: 0.353422, acc: 0.882812]\n",
      "215: [D loss: 1.344862, acc: 0.503906]  [A loss: 4.880167, acc: 0.000000]\n",
      "216: [D loss: 0.837822, acc: 0.580078]  [A loss: 0.068738, acc: 1.000000]\n",
      "217: [D loss: 1.636848, acc: 0.500000]  [A loss: 2.412342, acc: 0.000000]\n",
      "218: [D loss: 0.665815, acc: 0.601562]  [A loss: 1.528819, acc: 0.093750]\n",
      "219: [D loss: 0.948720, acc: 0.511719]  [A loss: 3.768501, acc: 0.000000]\n",
      "220: [D loss: 0.710117, acc: 0.587891]  [A loss: 0.479599, acc: 0.796875]\n",
      "221: [D loss: 1.244234, acc: 0.500000]  [A loss: 5.285566, acc: 0.000000]\n",
      "222: [D loss: 0.841891, acc: 0.603516]  [A loss: 0.034743, acc: 1.000000]\n",
      "223: [D loss: 1.992123, acc: 0.500000]  [A loss: 2.040307, acc: 0.027344]\n",
      "224: [D loss: 0.756600, acc: 0.539062]  [A loss: 2.124403, acc: 0.019531]\n",
      "225: [D loss: 0.848398, acc: 0.552734]  [A loss: 3.592958, acc: 0.000000]\n",
      "226: [D loss: 0.676294, acc: 0.578125]  [A loss: 1.410612, acc: 0.121094]\n",
      "227: [D loss: 1.092233, acc: 0.496094]  [A loss: 6.078381, acc: 0.000000]\n",
      "228: [D loss: 0.939769, acc: 0.550781]  [A loss: 0.012941, acc: 1.000000]\n",
      "229: [D loss: 2.344940, acc: 0.500000]  [A loss: 2.383105, acc: 0.023438]\n",
      "230: [D loss: 0.798709, acc: 0.541016]  [A loss: 3.070149, acc: 0.000000]\n",
      "231: [D loss: 0.787154, acc: 0.562500]  [A loss: 2.668424, acc: 0.003906]\n",
      "232: [D loss: 0.955735, acc: 0.521484]  [A loss: 5.908967, acc: 0.000000]\n",
      "233: [D loss: 0.798871, acc: 0.611328]  [A loss: 0.028521, acc: 1.000000]\n",
      "234: [D loss: 1.998685, acc: 0.500000]  [A loss: 3.652537, acc: 0.000000]\n",
      "235: [D loss: 0.689196, acc: 0.615234]  [A loss: 0.579712, acc: 0.652344]\n",
      "236: [D loss: 1.288794, acc: 0.498047]  [A loss: 6.709548, acc: 0.000000]\n",
      "237: [D loss: 1.063912, acc: 0.550781]  [A loss: 0.007804, acc: 1.000000]\n",
      "238: [D loss: 2.555929, acc: 0.500000]  [A loss: 1.246065, acc: 0.210938]\n",
      "239: [D loss: 0.999305, acc: 0.519531]  [A loss: 3.818118, acc: 0.000000]\n",
      "240: [D loss: 0.697729, acc: 0.628906]  [A loss: 0.549966, acc: 0.726562]\n",
      "241: [D loss: 1.260498, acc: 0.507812]  [A loss: 5.497396, acc: 0.000000]\n",
      "242: [D loss: 0.825490, acc: 0.619141]  [A loss: 0.052715, acc: 0.996094]\n",
      "243: [D loss: 1.795261, acc: 0.500000]  [A loss: 3.063166, acc: 0.007812]\n",
      "244: [D loss: 0.663250, acc: 0.642578]  [A loss: 0.916251, acc: 0.386719]\n",
      "245: [D loss: 1.100382, acc: 0.513672]  [A loss: 4.844522, acc: 0.000000]\n",
      "246: [D loss: 0.741928, acc: 0.619141]  [A loss: 0.145735, acc: 0.980469]\n",
      "247: [D loss: 1.535570, acc: 0.501953]  [A loss: 5.183734, acc: 0.000000]\n",
      "248: [D loss: 0.758967, acc: 0.652344]  [A loss: 0.075383, acc: 1.000000]\n",
      "249: [D loss: 1.809811, acc: 0.500000]  [A loss: 3.658734, acc: 0.000000]\n",
      "250: [D loss: 0.656766, acc: 0.628906]  [A loss: 0.639424, acc: 0.613281]\n",
      "251: [D loss: 1.258489, acc: 0.496094]  [A loss: 5.598657, acc: 0.000000]\n",
      "252: [D loss: 0.757548, acc: 0.603516]  [A loss: 0.089537, acc: 0.992188]\n",
      "253: [D loss: 1.716187, acc: 0.500000]  [A loss: 4.115141, acc: 0.000000]\n",
      "254: [D loss: 0.753180, acc: 0.597656]  [A loss: 0.207091, acc: 0.964844]\n",
      "255: [D loss: 1.369079, acc: 0.505859]  [A loss: 4.110376, acc: 0.000000]\n",
      "256: [D loss: 0.701281, acc: 0.609375]  [A loss: 0.368812, acc: 0.878906]\n",
      "257: [D loss: 1.429067, acc: 0.501953]  [A loss: 5.070834, acc: 0.000000]\n",
      "258: [D loss: 0.800869, acc: 0.593750]  [A loss: 0.093726, acc: 1.000000]\n",
      "259: [D loss: 1.724972, acc: 0.501953]  [A loss: 3.200321, acc: 0.000000]\n",
      "260: [D loss: 0.646683, acc: 0.625000]  [A loss: 0.887390, acc: 0.421875]\n",
      "261: [D loss: 1.186080, acc: 0.498047]  [A loss: 4.391413, acc: 0.000000]\n",
      "262: [D loss: 0.748683, acc: 0.595703]  [A loss: 0.245510, acc: 0.929688]\n",
      "263: [D loss: 1.520476, acc: 0.498047]  [A loss: 4.876251, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264: [D loss: 0.837902, acc: 0.599609]  [A loss: 0.069182, acc: 1.000000]\n",
      "265: [D loss: 1.853369, acc: 0.500000]  [A loss: 2.891843, acc: 0.000000]\n",
      "266: [D loss: 0.691845, acc: 0.595703]  [A loss: 1.137747, acc: 0.230469]\n",
      "267: [D loss: 1.180488, acc: 0.490234]  [A loss: 5.085429, acc: 0.000000]\n",
      "268: [D loss: 0.744695, acc: 0.599609]  [A loss: 0.208914, acc: 0.968750]\n",
      "269: [D loss: 1.518743, acc: 0.498047]  [A loss: 4.449958, acc: 0.000000]\n",
      "270: [D loss: 0.789261, acc: 0.572266]  [A loss: 0.161880, acc: 0.996094]\n",
      "271: [D loss: 1.606058, acc: 0.500000]  [A loss: 4.178552, acc: 0.000000]\n",
      "272: [D loss: 0.738714, acc: 0.583984]  [A loss: 0.282517, acc: 0.929688]\n",
      "273: [D loss: 1.456501, acc: 0.496094]  [A loss: 4.500454, acc: 0.000000]\n",
      "274: [D loss: 0.723868, acc: 0.619141]  [A loss: 0.172728, acc: 0.992188]\n",
      "275: [D loss: 1.354809, acc: 0.501953]  [A loss: 3.755240, acc: 0.000000]\n",
      "276: [D loss: 0.717195, acc: 0.607422]  [A loss: 0.297775, acc: 0.933594]\n",
      "277: [D loss: 1.415162, acc: 0.496094]  [A loss: 4.832827, acc: 0.000000]\n",
      "278: [D loss: 0.773128, acc: 0.626953]  [A loss: 0.157793, acc: 0.984375]\n",
      "279: [D loss: 1.581836, acc: 0.501953]  [A loss: 4.164376, acc: 0.000000]\n",
      "280: [D loss: 0.694500, acc: 0.613281]  [A loss: 0.297590, acc: 0.949219]\n",
      "281: [D loss: 1.282213, acc: 0.496094]  [A loss: 4.180774, acc: 0.000000]\n",
      "282: [D loss: 0.702055, acc: 0.607422]  [A loss: 0.334291, acc: 0.910156]\n",
      "283: [D loss: 1.346826, acc: 0.494141]  [A loss: 4.408504, acc: 0.000000]\n",
      "284: [D loss: 0.657724, acc: 0.650391]  [A loss: 0.288048, acc: 0.929688]\n",
      "285: [D loss: 1.297003, acc: 0.500000]  [A loss: 4.006967, acc: 0.000000]\n",
      "286: [D loss: 0.728217, acc: 0.578125]  [A loss: 0.303794, acc: 0.941406]\n",
      "287: [D loss: 1.403294, acc: 0.501953]  [A loss: 4.689480, acc: 0.000000]\n",
      "288: [D loss: 0.783352, acc: 0.576172]  [A loss: 0.130256, acc: 1.000000]\n",
      "289: [D loss: 1.542746, acc: 0.500000]  [A loss: 3.449880, acc: 0.000000]\n",
      "290: [D loss: 0.690724, acc: 0.574219]  [A loss: 0.520657, acc: 0.734375]\n",
      "291: [D loss: 1.252573, acc: 0.498047]  [A loss: 5.214241, acc: 0.000000]\n",
      "292: [D loss: 0.755154, acc: 0.580078]  [A loss: 0.149848, acc: 0.992188]\n",
      "293: [D loss: 1.525239, acc: 0.500000]  [A loss: 4.400113, acc: 0.000000]\n",
      "294: [D loss: 0.725213, acc: 0.597656]  [A loss: 0.271626, acc: 0.925781]\n",
      "295: [D loss: 1.396410, acc: 0.496094]  [A loss: 4.876183, acc: 0.000000]\n",
      "296: [D loss: 0.756297, acc: 0.578125]  [A loss: 0.121241, acc: 0.980469]\n",
      "297: [D loss: 1.647918, acc: 0.500000]  [A loss: 4.524566, acc: 0.000000]\n",
      "298: [D loss: 0.739061, acc: 0.615234]  [A loss: 0.204802, acc: 0.960938]\n",
      "299: [D loss: 1.440946, acc: 0.501953]  [A loss: 4.559668, acc: 0.000000]\n",
      "300: [D loss: 0.708399, acc: 0.611328]  [A loss: 0.580851, acc: 0.679688]\n",
      "301: [D loss: 1.442441, acc: 0.503906]  [A loss: 6.560065, acc: 0.000000]\n",
      "302: [D loss: 0.884833, acc: 0.589844]  [A loss: 0.027819, acc: 1.000000]\n",
      "303: [D loss: 2.200430, acc: 0.500000]  [A loss: 2.545779, acc: 0.000000]\n",
      "304: [D loss: 0.786795, acc: 0.556641]  [A loss: 2.343869, acc: 0.019531]\n",
      "305: [D loss: 0.971235, acc: 0.529297]  [A loss: 4.670760, acc: 0.000000]\n",
      "306: [D loss: 0.693392, acc: 0.591797]  [A loss: 0.582715, acc: 0.691406]\n",
      "307: [D loss: 1.384580, acc: 0.498047]  [A loss: 6.438891, acc: 0.000000]\n",
      "308: [D loss: 1.111515, acc: 0.519531]  [A loss: 0.009940, acc: 1.000000]\n",
      "309: [D loss: 2.760285, acc: 0.500000]  [A loss: 2.050694, acc: 0.011719]\n",
      "310: [D loss: 0.956664, acc: 0.527344]  [A loss: 3.707581, acc: 0.000000]\n",
      "311: [D loss: 0.770318, acc: 0.542969]  [A loss: 1.113645, acc: 0.257812]\n",
      "312: [D loss: 1.298658, acc: 0.496094]  [A loss: 6.604915, acc: 0.000000]\n",
      "313: [D loss: 0.934376, acc: 0.558594]  [A loss: 0.033174, acc: 1.000000]\n",
      "314: [D loss: 2.134014, acc: 0.500000]  [A loss: 2.724653, acc: 0.007812]\n",
      "315: [D loss: 0.721552, acc: 0.570312]  [A loss: 1.466606, acc: 0.148438]\n",
      "316: [D loss: 1.059060, acc: 0.492188]  [A loss: 4.431255, acc: 0.000000]\n",
      "317: [D loss: 0.710883, acc: 0.626953]  [A loss: 0.238628, acc: 0.949219]\n",
      "318: [D loss: 1.524443, acc: 0.494141]  [A loss: 5.009310, acc: 0.000000]\n",
      "319: [D loss: 0.857126, acc: 0.578125]  [A loss: 0.060650, acc: 1.000000]\n",
      "320: [D loss: 1.814324, acc: 0.500000]  [A loss: 3.142316, acc: 0.000000]\n",
      "321: [D loss: 0.744485, acc: 0.568359]  [A loss: 1.525077, acc: 0.132812]\n",
      "322: [D loss: 1.195724, acc: 0.490234]  [A loss: 5.570611, acc: 0.000000]\n",
      "323: [D loss: 0.824024, acc: 0.580078]  [A loss: 0.109305, acc: 0.980469]\n",
      "324: [D loss: 1.743742, acc: 0.498047]  [A loss: 5.091719, acc: 0.000000]\n",
      "325: [D loss: 0.755910, acc: 0.582031]  [A loss: 0.194190, acc: 0.957031]\n",
      "326: [D loss: 1.501317, acc: 0.500000]  [A loss: 4.897107, acc: 0.000000]\n",
      "327: [D loss: 0.763837, acc: 0.585938]  [A loss: 0.213284, acc: 0.957031]\n",
      "328: [D loss: 1.486916, acc: 0.501953]  [A loss: 4.811801, acc: 0.000000]\n",
      "329: [D loss: 0.747251, acc: 0.648438]  [A loss: 0.120452, acc: 0.996094]\n",
      "330: [D loss: 1.649516, acc: 0.498047]  [A loss: 4.023815, acc: 0.003906]\n",
      "331: [D loss: 0.722317, acc: 0.585938]  [A loss: 0.351546, acc: 0.867188]\n",
      "332: [D loss: 1.228929, acc: 0.509766]  [A loss: 4.381678, acc: 0.000000]\n",
      "333: [D loss: 0.740042, acc: 0.572266]  [A loss: 0.450831, acc: 0.796875]\n",
      "334: [D loss: 1.475663, acc: 0.501953]  [A loss: 6.690973, acc: 0.000000]\n",
      "335: [D loss: 0.899535, acc: 0.576172]  [A loss: 0.025783, acc: 1.000000]\n",
      "336: [D loss: 2.251038, acc: 0.500000]  [A loss: 2.731168, acc: 0.011719]\n",
      "337: [D loss: 0.756943, acc: 0.572266]  [A loss: 2.317382, acc: 0.015625]\n",
      "338: [D loss: 1.060170, acc: 0.511719]  [A loss: 5.745008, acc: 0.000000]\n",
      "339: [D loss: 0.751102, acc: 0.580078]  [A loss: 0.210649, acc: 0.964844]\n",
      "340: [D loss: 1.481714, acc: 0.501953]  [A loss: 6.337093, acc: 0.000000]\n",
      "341: [D loss: 0.949454, acc: 0.568359]  [A loss: 0.019617, acc: 1.000000]\n",
      "342: [D loss: 2.306838, acc: 0.500000]  [A loss: 2.770316, acc: 0.007812]\n",
      "343: [D loss: 1.083737, acc: 0.503906]  [A loss: 4.786673, acc: 0.000000]\n",
      "344: [D loss: 0.811841, acc: 0.556641]  [A loss: 1.234096, acc: 0.308594]\n",
      "345: [D loss: 1.681350, acc: 0.509766]  [A loss: 10.260881, acc: 0.000000]\n",
      "346: [D loss: 1.754296, acc: 0.511719]  [A loss: 0.001149, acc: 1.000000]\n",
      "347: [D loss: 4.302408, acc: 0.500000]  [A loss: 1.348750, acc: 0.222656]\n",
      "348: [D loss: 1.357361, acc: 0.501953]  [A loss: 5.187582, acc: 0.000000]\n",
      "349: [D loss: 0.875189, acc: 0.531250]  [A loss: 0.376801, acc: 0.847656]\n",
      "350: [D loss: 1.609248, acc: 0.492188]  [A loss: 5.750946, acc: 0.000000]\n",
      "351: [D loss: 0.902678, acc: 0.560547]  [A loss: 0.187626, acc: 0.960938]\n",
      "352: [D loss: 1.747465, acc: 0.501953]  [A loss: 5.261872, acc: 0.000000]\n",
      "353: [D loss: 0.744606, acc: 0.621094]  [A loss: 0.418027, acc: 0.808594]\n",
      "354: [D loss: 1.516025, acc: 0.507812]  [A loss: 5.525338, acc: 0.000000]\n",
      "355: [D loss: 0.817842, acc: 0.568359]  [A loss: 0.154210, acc: 0.976562]\n",
      "356: [D loss: 1.584175, acc: 0.494141]  [A loss: 4.230606, acc: 0.000000]\n",
      "357: [D loss: 0.693693, acc: 0.613281]  [A loss: 0.509461, acc: 0.738281]\n",
      "358: [D loss: 1.445385, acc: 0.498047]  [A loss: 5.427922, acc: 0.000000]\n",
      "359: [D loss: 0.785038, acc: 0.580078]  [A loss: 0.158000, acc: 0.976562]\n",
      "360: [D loss: 1.677026, acc: 0.501953]  [A loss: 4.594281, acc: 0.000000]\n",
      "361: [D loss: 0.763654, acc: 0.589844]  [A loss: 0.303988, acc: 0.878906]\n",
      "362: [D loss: 1.497509, acc: 0.503906]  [A loss: 5.569826, acc: 0.000000]\n",
      "363: [D loss: 0.882057, acc: 0.562500]  [A loss: 0.075211, acc: 1.000000]\n",
      "364: [D loss: 1.765924, acc: 0.500000]  [A loss: 3.582880, acc: 0.003906]\n",
      "365: [D loss: 0.694091, acc: 0.619141]  [A loss: 1.050590, acc: 0.355469]\n",
      "366: [D loss: 1.268157, acc: 0.490234]  [A loss: 6.077423, acc: 0.000000]\n",
      "367: [D loss: 0.845977, acc: 0.591797]  [A loss: 0.099430, acc: 0.996094]\n",
      "368: [D loss: 1.654396, acc: 0.501953]  [A loss: 4.729357, acc: 0.000000]\n",
      "369: [D loss: 0.789343, acc: 0.582031]  [A loss: 0.209337, acc: 0.937500]\n",
      "370: [D loss: 1.566697, acc: 0.503906]  [A loss: 5.206217, acc: 0.000000]\n",
      "371: [D loss: 0.802987, acc: 0.601562]  [A loss: 0.189879, acc: 0.960938]\n",
      "372: [D loss: 1.655069, acc: 0.500000]  [A loss: 5.494297, acc: 0.000000]\n",
      "373: [D loss: 0.822373, acc: 0.607422]  [A loss: 0.142574, acc: 0.968750]\n",
      "374: [D loss: 1.736625, acc: 0.503906]  [A loss: 5.314914, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375: [D loss: 0.836440, acc: 0.550781]  [A loss: 0.299609, acc: 0.882812]\n",
      "376: [D loss: 1.618542, acc: 0.511719]  [A loss: 7.417328, acc: 0.000000]\n",
      "377: [D loss: 0.926536, acc: 0.625000]  [A loss: 0.032838, acc: 1.000000]\n",
      "378: [D loss: 2.173102, acc: 0.500000]  [A loss: 2.793283, acc: 0.007812]\n",
      "379: [D loss: 0.827770, acc: 0.560547]  [A loss: 2.703800, acc: 0.027344]\n",
      "380: [D loss: 0.968613, acc: 0.531250]  [A loss: 3.866479, acc: 0.003906]\n",
      "381: [D loss: 0.840668, acc: 0.533203]  [A loss: 2.626723, acc: 0.019531]\n",
      "382: [D loss: 1.206310, acc: 0.515625]  [A loss: 7.409776, acc: 0.000000]\n",
      "383: [D loss: 1.077462, acc: 0.568359]  [A loss: 0.007955, acc: 1.000000]\n",
      "384: [D loss: 3.256565, acc: 0.500000]  [A loss: 3.271236, acc: 0.015625]\n",
      "385: [D loss: 1.047195, acc: 0.541016]  [A loss: 4.730748, acc: 0.000000]\n",
      "386: [D loss: 0.806357, acc: 0.576172]  [A loss: 1.650114, acc: 0.171875]\n",
      "387: [D loss: 1.331264, acc: 0.503906]  [A loss: 8.024754, acc: 0.000000]\n",
      "388: [D loss: 1.377531, acc: 0.517578]  [A loss: 0.005323, acc: 1.000000]\n",
      "389: [D loss: 3.435829, acc: 0.500000]  [A loss: 1.548401, acc: 0.203125]\n",
      "390: [D loss: 1.163806, acc: 0.531250]  [A loss: 4.701879, acc: 0.000000]\n",
      "391: [D loss: 0.900027, acc: 0.517578]  [A loss: 0.478519, acc: 0.734375]\n",
      "392: [D loss: 1.630839, acc: 0.496094]  [A loss: 7.335664, acc: 0.000000]\n",
      "393: [D loss: 1.157700, acc: 0.539062]  [A loss: 0.024196, acc: 1.000000]\n",
      "394: [D loss: 2.576548, acc: 0.500000]  [A loss: 3.021993, acc: 0.011719]\n",
      "395: [D loss: 1.048934, acc: 0.498047]  [A loss: 3.876407, acc: 0.000000]\n",
      "396: [D loss: 0.882070, acc: 0.548828]  [A loss: 2.827235, acc: 0.015625]\n",
      "397: [D loss: 1.225658, acc: 0.513672]  [A loss: 6.628594, acc: 0.000000]\n",
      "398: [D loss: 0.895116, acc: 0.582031]  [A loss: 0.122964, acc: 0.976562]\n",
      "399: [D loss: 1.781237, acc: 0.503906]  [A loss: 5.717706, acc: 0.000000]\n",
      "400: [D loss: 0.843765, acc: 0.599609]  [A loss: 0.127382, acc: 0.976562]\n",
      "401: [D loss: 1.704264, acc: 0.500000]  [A loss: 5.361514, acc: 0.000000]\n",
      "402: [D loss: 0.808455, acc: 0.613281]  [A loss: 0.128346, acc: 0.980469]\n",
      "403: [D loss: 1.886375, acc: 0.503906]  [A loss: 5.282063, acc: 0.000000]\n",
      "404: [D loss: 0.769146, acc: 0.611328]  [A loss: 0.415605, acc: 0.804688]\n",
      "405: [D loss: 1.562165, acc: 0.503906]  [A loss: 7.481261, acc: 0.000000]\n",
      "406: [D loss: 1.041466, acc: 0.562500]  [A loss: 0.042921, acc: 1.000000]\n",
      "407: [D loss: 2.464009, acc: 0.501953]  [A loss: 4.546004, acc: 0.000000]\n",
      "408: [D loss: 0.776371, acc: 0.611328]  [A loss: 0.565252, acc: 0.699219]\n",
      "409: [D loss: 1.409608, acc: 0.525391]  [A loss: 5.767144, acc: 0.000000]\n",
      "410: [D loss: 0.933238, acc: 0.548828]  [A loss: 0.069028, acc: 0.992188]\n",
      "411: [D loss: 2.093665, acc: 0.501953]  [A loss: 3.985409, acc: 0.000000]\n",
      "412: [D loss: 0.723496, acc: 0.599609]  [A loss: 1.148127, acc: 0.363281]\n",
      "413: [D loss: 1.453644, acc: 0.505859]  [A loss: 6.982079, acc: 0.000000]\n",
      "414: [D loss: 1.153321, acc: 0.541016]  [A loss: 0.027130, acc: 1.000000]\n",
      "415: [D loss: 2.678373, acc: 0.500000]  [A loss: 2.912615, acc: 0.015625]\n",
      "416: [D loss: 0.900555, acc: 0.542969]  [A loss: 2.463552, acc: 0.019531]\n",
      "417: [D loss: 1.145435, acc: 0.533203]  [A loss: 5.224930, acc: 0.000000]\n",
      "418: [D loss: 0.880033, acc: 0.548828]  [A loss: 0.698749, acc: 0.593750]\n",
      "419: [D loss: 1.687113, acc: 0.492188]  [A loss: 9.217138, acc: 0.000000]\n",
      "420: [D loss: 1.571073, acc: 0.523438]  [A loss: 0.010278, acc: 1.000000]\n",
      "421: [D loss: 3.004091, acc: 0.500000]  [A loss: 1.937526, acc: 0.117188]\n",
      "422: [D loss: 1.117368, acc: 0.550781]  [A loss: 4.198346, acc: 0.000000]\n",
      "423: [D loss: 0.751755, acc: 0.595703]  [A loss: 1.399366, acc: 0.218750]\n",
      "424: [D loss: 1.251843, acc: 0.523438]  [A loss: 5.829566, acc: 0.000000]\n",
      "425: [D loss: 0.832240, acc: 0.580078]  [A loss: 0.165213, acc: 0.972656]\n",
      "426: [D loss: 1.774345, acc: 0.500000]  [A loss: 5.682607, acc: 0.000000]\n",
      "427: [D loss: 0.835342, acc: 0.583984]  [A loss: 0.147915, acc: 0.968750]\n",
      "428: [D loss: 1.615494, acc: 0.500000]  [A loss: 4.971793, acc: 0.000000]\n",
      "429: [D loss: 0.875773, acc: 0.539062]  [A loss: 0.353623, acc: 0.851562]\n",
      "430: [D loss: 1.461105, acc: 0.515625]  [A loss: 5.568612, acc: 0.000000]\n",
      "431: [D loss: 0.859633, acc: 0.562500]  [A loss: 0.139171, acc: 0.968750]\n",
      "432: [D loss: 1.889625, acc: 0.507812]  [A loss: 5.757811, acc: 0.000000]\n",
      "433: [D loss: 0.848419, acc: 0.611328]  [A loss: 0.109120, acc: 0.992188]\n",
      "434: [D loss: 1.734627, acc: 0.507812]  [A loss: 3.715017, acc: 0.003906]\n",
      "435: [D loss: 0.682100, acc: 0.625000]  [A loss: 0.929623, acc: 0.472656]\n",
      "436: [D loss: 1.156788, acc: 0.517578]  [A loss: 4.650671, acc: 0.000000]\n",
      "437: [D loss: 0.767594, acc: 0.603516]  [A loss: 0.230464, acc: 0.925781]\n",
      "438: [D loss: 1.598504, acc: 0.498047]  [A loss: 5.356496, acc: 0.000000]\n",
      "439: [D loss: 0.801226, acc: 0.572266]  [A loss: 0.115606, acc: 0.980469]\n",
      "440: [D loss: 1.933364, acc: 0.501953]  [A loss: 4.378914, acc: 0.000000]\n",
      "441: [D loss: 0.807360, acc: 0.556641]  [A loss: 1.347669, acc: 0.292969]\n",
      "442: [D loss: 1.540193, acc: 0.490234]  [A loss: 8.305318, acc: 0.000000]\n",
      "443: [D loss: 1.117877, acc: 0.546875]  [A loss: 0.017443, acc: 1.000000]\n",
      "444: [D loss: 3.080408, acc: 0.500000]  [A loss: 4.626573, acc: 0.000000]\n",
      "445: [D loss: 0.934729, acc: 0.539062]  [A loss: 4.297608, acc: 0.003906]\n",
      "446: [D loss: 1.076833, acc: 0.539062]  [A loss: 6.684925, acc: 0.000000]\n",
      "447: [D loss: 0.898380, acc: 0.542969]  [A loss: 0.721483, acc: 0.632812]\n",
      "448: [D loss: 1.828686, acc: 0.505859]  [A loss: 10.662088, acc: 0.000000]\n",
      "449: [D loss: 1.952683, acc: 0.505859]  [A loss: 0.003366, acc: 1.000000]\n",
      "450: [D loss: 3.721755, acc: 0.500000]  [A loss: 0.981523, acc: 0.402344]\n",
      "451: [D loss: 1.117262, acc: 0.531250]  [A loss: 3.688241, acc: 0.000000]\n",
      "452: [D loss: 0.774751, acc: 0.574219]  [A loss: 1.632773, acc: 0.156250]\n",
      "453: [D loss: 1.232726, acc: 0.501953]  [A loss: 5.825131, acc: 0.000000]\n",
      "454: [D loss: 0.880679, acc: 0.570312]  [A loss: 0.136311, acc: 0.968750]\n",
      "455: [D loss: 1.880901, acc: 0.503906]  [A loss: 5.747924, acc: 0.003906]\n",
      "456: [D loss: 0.836469, acc: 0.580078]  [A loss: 0.131948, acc: 0.960938]\n",
      "457: [D loss: 1.871302, acc: 0.503906]  [A loss: 5.885386, acc: 0.000000]\n",
      "458: [D loss: 0.864270, acc: 0.580078]  [A loss: 0.107921, acc: 0.976562]\n",
      "459: [D loss: 1.873366, acc: 0.501953]  [A loss: 5.253427, acc: 0.000000]\n",
      "460: [D loss: 0.755559, acc: 0.626953]  [A loss: 0.577102, acc: 0.699219]\n",
      "461: [D loss: 1.511612, acc: 0.507812]  [A loss: 6.590186, acc: 0.000000]\n",
      "462: [D loss: 0.899633, acc: 0.580078]  [A loss: 0.086468, acc: 0.984375]\n",
      "463: [D loss: 2.139691, acc: 0.503906]  [A loss: 5.909502, acc: 0.000000]\n",
      "464: [D loss: 0.856635, acc: 0.597656]  [A loss: 0.135623, acc: 0.976562]\n",
      "465: [D loss: 1.739011, acc: 0.511719]  [A loss: 5.584935, acc: 0.000000]\n",
      "466: [D loss: 0.764377, acc: 0.613281]  [A loss: 0.205359, acc: 0.937500]\n",
      "467: [D loss: 1.737117, acc: 0.503906]  [A loss: 6.272297, acc: 0.000000]\n",
      "468: [D loss: 0.786200, acc: 0.634766]  [A loss: 0.142998, acc: 0.972656]\n",
      "469: [D loss: 1.729309, acc: 0.500000]  [A loss: 4.436534, acc: 0.000000]\n",
      "470: [D loss: 0.686807, acc: 0.628906]  [A loss: 1.208444, acc: 0.273438]\n",
      "471: [D loss: 1.469849, acc: 0.503906]  [A loss: 7.152884, acc: 0.000000]\n",
      "472: [D loss: 1.009266, acc: 0.546875]  [A loss: 0.027204, acc: 1.000000]\n",
      "473: [D loss: 2.596567, acc: 0.500000]  [A loss: 3.482701, acc: 0.007812]\n",
      "474: [D loss: 0.945511, acc: 0.533203]  [A loss: 4.421173, acc: 0.003906]\n",
      "475: [D loss: 0.970674, acc: 0.560547]  [A loss: 3.846191, acc: 0.000000]\n",
      "476: [D loss: 1.090002, acc: 0.494141]  [A loss: 5.852829, acc: 0.000000]\n",
      "477: [D loss: 0.864374, acc: 0.537109]  [A loss: 1.796611, acc: 0.156250]\n",
      "478: [D loss: 1.981760, acc: 0.500000]  [A loss: 12.842800, acc: 0.000000]\n",
      "479: [D loss: 3.015519, acc: 0.500000]  [A loss: 0.001371, acc: 1.000000]\n",
      "480: [D loss: 4.606813, acc: 0.500000]  [A loss: 1.299219, acc: 0.339844]\n",
      "481: [D loss: 1.262385, acc: 0.521484]  [A loss: 5.093090, acc: 0.000000]\n",
      "482: [D loss: 0.855864, acc: 0.544922]  [A loss: 1.620953, acc: 0.179688]\n",
      "483: [D loss: 1.585122, acc: 0.507812]  [A loss: 7.847752, acc: 0.000000]\n",
      "484: [D loss: 1.133357, acc: 0.550781]  [A loss: 0.021908, acc: 1.000000]\n",
      "485: [D loss: 2.883029, acc: 0.503906]  [A loss: 4.708886, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486: [D loss: 0.933598, acc: 0.580078]  [A loss: 2.641241, acc: 0.046875]\n",
      "487: [D loss: 1.368759, acc: 0.496094]  [A loss: 6.659832, acc: 0.000000]\n",
      "488: [D loss: 0.885459, acc: 0.564453]  [A loss: 0.211516, acc: 0.902344]\n",
      "489: [D loss: 1.993612, acc: 0.507812]  [A loss: 7.475354, acc: 0.000000]\n",
      "490: [D loss: 1.105865, acc: 0.552734]  [A loss: 0.029764, acc: 0.996094]\n",
      "491: [D loss: 2.571739, acc: 0.500000]  [A loss: 4.128780, acc: 0.000000]\n",
      "492: [D loss: 0.911002, acc: 0.527344]  [A loss: 2.165096, acc: 0.082031]\n",
      "493: [D loss: 1.334751, acc: 0.507812]  [A loss: 6.601910, acc: 0.000000]\n",
      "494: [D loss: 0.880492, acc: 0.597656]  [A loss: 0.286190, acc: 0.886719]\n",
      "495: [D loss: 1.772302, acc: 0.505859]  [A loss: 8.456185, acc: 0.000000]\n",
      "496: [D loss: 1.347291, acc: 0.509766]  [A loss: 0.011028, acc: 1.000000]\n",
      "497: [D loss: 3.146054, acc: 0.500000]  [A loss: 2.583231, acc: 0.054688]\n",
      "498: [D loss: 1.024714, acc: 0.533203]  [A loss: 3.902690, acc: 0.003906]\n",
      "499: [D loss: 0.908496, acc: 0.548828]  [A loss: 2.865869, acc: 0.027344]\n",
      "500: [D loss: 1.326331, acc: 0.501953]  [A loss: 7.157602, acc: 0.000000]\n",
      "501: [D loss: 0.978301, acc: 0.560547]  [A loss: 0.074115, acc: 0.988281]\n",
      "502: [D loss: 2.416065, acc: 0.505859]  [A loss: 7.032231, acc: 0.000000]\n",
      "503: [D loss: 0.913027, acc: 0.628906]  [A loss: 0.060098, acc: 0.992188]\n",
      "504: [D loss: 2.236824, acc: 0.505859]  [A loss: 6.170168, acc: 0.000000]\n",
      "505: [D loss: 0.775386, acc: 0.615234]  [A loss: 0.181346, acc: 0.941406]\n",
      "506: [D loss: 1.662517, acc: 0.515625]  [A loss: 5.808086, acc: 0.000000]\n",
      "507: [D loss: 0.828596, acc: 0.621094]  [A loss: 0.265789, acc: 0.898438]\n",
      "508: [D loss: 1.549617, acc: 0.507812]  [A loss: 6.474060, acc: 0.000000]\n",
      "509: [D loss: 0.864088, acc: 0.625000]  [A loss: 0.086641, acc: 0.984375]\n",
      "510: [D loss: 2.050018, acc: 0.507812]  [A loss: 5.080874, acc: 0.003906]\n",
      "511: [D loss: 0.796211, acc: 0.576172]  [A loss: 0.614987, acc: 0.652344]\n",
      "512: [D loss: 1.658846, acc: 0.501953]  [A loss: 7.955718, acc: 0.000000]\n",
      "513: [D loss: 1.035928, acc: 0.572266]  [A loss: 0.027846, acc: 1.000000]\n",
      "514: [D loss: 2.819110, acc: 0.500000]  [A loss: 4.519346, acc: 0.000000]\n",
      "515: [D loss: 0.815837, acc: 0.609375]  [A loss: 2.273341, acc: 0.078125]\n",
      "516: [D loss: 1.383187, acc: 0.515625]  [A loss: 8.478695, acc: 0.000000]\n",
      "517: [D loss: 1.035230, acc: 0.580078]  [A loss: 0.021517, acc: 1.000000]\n",
      "518: [D loss: 3.151213, acc: 0.500000]  [A loss: 5.985574, acc: 0.000000]\n",
      "519: [D loss: 1.057278, acc: 0.537109]  [A loss: 3.563179, acc: 0.035156]\n",
      "520: [D loss: 1.470594, acc: 0.529297]  [A loss: 10.075335, acc: 0.000000]\n",
      "521: [D loss: 1.309162, acc: 0.564453]  [A loss: 0.005704, acc: 1.000000]\n",
      "522: [D loss: 4.031414, acc: 0.500000]  [A loss: 3.436380, acc: 0.019531]\n",
      "523: [D loss: 1.240864, acc: 0.537109]  [A loss: 7.237689, acc: 0.000000]\n",
      "524: [D loss: 0.931234, acc: 0.603516]  [A loss: 0.127533, acc: 0.972656]\n",
      "525: [D loss: 1.837489, acc: 0.505859]  [A loss: 6.227445, acc: 0.000000]\n",
      "526: [D loss: 0.860792, acc: 0.587891]  [A loss: 0.292067, acc: 0.859375]\n",
      "527: [D loss: 1.725327, acc: 0.515625]  [A loss: 6.820559, acc: 0.000000]\n",
      "528: [D loss: 0.914611, acc: 0.568359]  [A loss: 0.247442, acc: 0.902344]\n",
      "529: [D loss: 1.744901, acc: 0.521484]  [A loss: 8.023314, acc: 0.000000]\n",
      "530: [D loss: 0.926186, acc: 0.583984]  [A loss: 0.052972, acc: 0.996094]\n",
      "531: [D loss: 2.395833, acc: 0.509766]  [A loss: 7.729520, acc: 0.000000]\n",
      "532: [D loss: 0.897364, acc: 0.601562]  [A loss: 0.095698, acc: 0.968750]\n",
      "533: [D loss: 1.982124, acc: 0.509766]  [A loss: 6.244875, acc: 0.000000]\n",
      "534: [D loss: 0.742113, acc: 0.636719]  [A loss: 0.884894, acc: 0.527344]\n",
      "535: [D loss: 1.720525, acc: 0.523438]  [A loss: 8.542940, acc: 0.000000]\n",
      "536: [D loss: 1.269965, acc: 0.591797]  [A loss: 0.005682, acc: 1.000000]\n",
      "537: [D loss: 3.842142, acc: 0.500000]  [A loss: 2.480443, acc: 0.062500]\n",
      "538: [D loss: 1.270237, acc: 0.562500]  [A loss: 6.109146, acc: 0.000000]\n",
      "539: [D loss: 0.842227, acc: 0.591797]  [A loss: 0.519201, acc: 0.726562]\n",
      "540: [D loss: 1.667144, acc: 0.511719]  [A loss: 7.949381, acc: 0.000000]\n",
      "541: [D loss: 1.034490, acc: 0.582031]  [A loss: 0.048207, acc: 0.992188]\n",
      "542: [D loss: 2.644968, acc: 0.500000]  [A loss: 5.136235, acc: 0.000000]\n",
      "543: [D loss: 0.930517, acc: 0.591797]  [A loss: 2.910835, acc: 0.085938]\n",
      "544: [D loss: 1.824208, acc: 0.500000]  [A loss: 11.011586, acc: 0.000000]\n",
      "545: [D loss: 1.508720, acc: 0.554688]  [A loss: 0.003213, acc: 1.000000]\n",
      "546: [D loss: 4.558766, acc: 0.500000]  [A loss: 4.131570, acc: 0.007812]\n",
      "547: [D loss: 1.584762, acc: 0.509766]  [A loss: 9.566164, acc: 0.000000]\n",
      "548: [D loss: 1.060621, acc: 0.591797]  [A loss: 0.070471, acc: 0.980469]\n",
      "549: [D loss: 2.649659, acc: 0.500000]  [A loss: 7.417041, acc: 0.000000]\n",
      "550: [D loss: 0.981882, acc: 0.554688]  [A loss: 0.147191, acc: 0.949219]\n",
      "551: [D loss: 2.117480, acc: 0.501953]  [A loss: 6.701900, acc: 0.000000]\n",
      "552: [D loss: 0.968957, acc: 0.574219]  [A loss: 0.149498, acc: 0.941406]\n",
      "553: [D loss: 2.223631, acc: 0.507812]  [A loss: 7.739512, acc: 0.000000]\n",
      "554: [D loss: 1.013918, acc: 0.572266]  [A loss: 0.181257, acc: 0.945312]\n",
      "555: [D loss: 1.977443, acc: 0.511719]  [A loss: 7.534687, acc: 0.000000]\n",
      "556: [D loss: 0.943718, acc: 0.582031]  [A loss: 0.331431, acc: 0.867188]\n",
      "557: [D loss: 1.923972, acc: 0.513672]  [A loss: 9.131273, acc: 0.000000]\n",
      "558: [D loss: 1.067659, acc: 0.589844]  [A loss: 0.094242, acc: 0.968750]\n",
      "559: [D loss: 2.397258, acc: 0.501953]  [A loss: 7.159412, acc: 0.000000]\n",
      "560: [D loss: 0.918982, acc: 0.621094]  [A loss: 0.202438, acc: 0.914062]\n",
      "561: [D loss: 2.049412, acc: 0.501953]  [A loss: 7.006063, acc: 0.000000]\n",
      "562: [D loss: 0.917135, acc: 0.597656]  [A loss: 0.128002, acc: 0.976562]\n",
      "563: [D loss: 2.009989, acc: 0.509766]  [A loss: 5.851050, acc: 0.000000]\n",
      "564: [D loss: 0.824784, acc: 0.605469]  [A loss: 0.432793, acc: 0.792969]\n",
      "565: [D loss: 1.671610, acc: 0.527344]  [A loss: 6.764317, acc: 0.000000]\n",
      "566: [D loss: 0.819968, acc: 0.607422]  [A loss: 0.242957, acc: 0.917969]\n",
      "567: [D loss: 1.832735, acc: 0.511719]  [A loss: 6.455148, acc: 0.003906]\n",
      "568: [D loss: 0.810473, acc: 0.619141]  [A loss: 0.362195, acc: 0.824219]\n",
      "569: [D loss: 1.802962, acc: 0.511719]  [A loss: 7.256040, acc: 0.000000]\n",
      "570: [D loss: 0.894992, acc: 0.619141]  [A loss: 0.188136, acc: 0.941406]\n",
      "571: [D loss: 2.030218, acc: 0.503906]  [A loss: 7.500058, acc: 0.000000]\n",
      "572: [D loss: 1.055943, acc: 0.552734]  [A loss: 0.090587, acc: 0.968750]\n",
      "573: [D loss: 2.257931, acc: 0.503906]  [A loss: 5.648046, acc: 0.000000]\n",
      "574: [D loss: 0.824122, acc: 0.605469]  [A loss: 0.833235, acc: 0.531250]\n",
      "575: [D loss: 1.864235, acc: 0.509766]  [A loss: 9.096233, acc: 0.000000]\n",
      "576: [D loss: 1.061251, acc: 0.574219]  [A loss: 0.026579, acc: 0.996094]\n",
      "577: [D loss: 3.041058, acc: 0.501953]  [A loss: 5.325691, acc: 0.003906]\n",
      "578: [D loss: 0.845120, acc: 0.589844]  [A loss: 1.970981, acc: 0.144531]\n",
      "579: [D loss: 1.555264, acc: 0.494141]  [A loss: 8.046003, acc: 0.000000]\n",
      "580: [D loss: 1.058823, acc: 0.535156]  [A loss: 0.465710, acc: 0.773438]\n",
      "581: [D loss: 2.295948, acc: 0.494141]  [A loss: 12.047142, acc: 0.000000]\n",
      "582: [D loss: 2.103068, acc: 0.523438]  [A loss: 0.002167, acc: 1.000000]\n",
      "583: [D loss: 4.740492, acc: 0.500000]  [A loss: 1.532276, acc: 0.261719]\n",
      "584: [D loss: 1.773618, acc: 0.505859]  [A loss: 7.142388, acc: 0.000000]\n",
      "585: [D loss: 0.881164, acc: 0.558594]  [A loss: 0.805105, acc: 0.554688]\n",
      "586: [D loss: 1.863278, acc: 0.513672]  [A loss: 7.423677, acc: 0.000000]\n",
      "587: [D loss: 0.967296, acc: 0.578125]  [A loss: 0.220871, acc: 0.921875]\n",
      "588: [D loss: 2.112636, acc: 0.509766]  [A loss: 7.517745, acc: 0.000000]\n",
      "589: [D loss: 0.983728, acc: 0.554688]  [A loss: 0.159538, acc: 0.960938]\n",
      "590: [D loss: 2.012966, acc: 0.503906]  [A loss: 5.778187, acc: 0.000000]\n",
      "591: [D loss: 0.832873, acc: 0.576172]  [A loss: 1.058200, acc: 0.441406]\n",
      "592: [D loss: 1.657332, acc: 0.494141]  [A loss: 7.916904, acc: 0.000000]\n",
      "593: [D loss: 1.059780, acc: 0.535156]  [A loss: 0.187959, acc: 0.933594]\n",
      "594: [D loss: 2.178396, acc: 0.500000]  [A loss: 9.371988, acc: 0.000000]\n",
      "595: [D loss: 1.201828, acc: 0.568359]  [A loss: 0.024424, acc: 1.000000]\n",
      "596: [D loss: 2.966781, acc: 0.500000]  [A loss: 4.167802, acc: 0.003906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597: [D loss: 0.953026, acc: 0.587891]  [A loss: 4.062750, acc: 0.003906]\n",
      "598: [D loss: 1.040650, acc: 0.533203]  [A loss: 4.433387, acc: 0.000000]\n",
      "599: [D loss: 1.058613, acc: 0.523438]  [A loss: 5.848564, acc: 0.000000]\n",
      "600: [D loss: 1.086012, acc: 0.490234]  [A loss: 3.053395, acc: 0.039062]\n",
      "601: [D loss: 1.875773, acc: 0.505859]  [A loss: 11.745180, acc: 0.000000]\n",
      "602: [D loss: 2.158331, acc: 0.500000]  [A loss: 0.003399, acc: 1.000000]\n",
      "603: [D loss: 4.956859, acc: 0.500000]  [A loss: 2.598980, acc: 0.078125]\n",
      "604: [D loss: 1.763906, acc: 0.490234]  [A loss: 8.714502, acc: 0.000000]\n",
      "605: [D loss: 1.197855, acc: 0.507812]  [A loss: 0.087779, acc: 0.980469]\n",
      "606: [D loss: 2.526787, acc: 0.507812]  [A loss: 7.670164, acc: 0.000000]\n",
      "607: [D loss: 1.083192, acc: 0.548828]  [A loss: 0.122818, acc: 0.960938]\n",
      "608: [D loss: 2.162415, acc: 0.511719]  [A loss: 6.273814, acc: 0.000000]\n",
      "609: [D loss: 1.000152, acc: 0.531250]  [A loss: 1.594661, acc: 0.289062]\n",
      "610: [D loss: 1.933477, acc: 0.507812]  [A loss: 10.238971, acc: 0.000000]\n",
      "611: [D loss: 1.445168, acc: 0.527344]  [A loss: 0.009815, acc: 1.000000]\n",
      "612: [D loss: 3.687006, acc: 0.501953]  [A loss: 5.346589, acc: 0.000000]\n",
      "613: [D loss: 0.937672, acc: 0.562500]  [A loss: 2.372597, acc: 0.101562]\n",
      "614: [D loss: 1.689134, acc: 0.496094]  [A loss: 9.285481, acc: 0.000000]\n",
      "615: [D loss: 1.213107, acc: 0.523438]  [A loss: 0.038273, acc: 0.996094]\n",
      "616: [D loss: 2.983611, acc: 0.500000]  [A loss: 7.304206, acc: 0.000000]\n",
      "617: [D loss: 1.038704, acc: 0.533203]  [A loss: 0.954030, acc: 0.515625]\n",
      "618: [D loss: 1.825071, acc: 0.511719]  [A loss: 10.124260, acc: 0.000000]\n",
      "619: [D loss: 1.400000, acc: 0.537109]  [A loss: 0.011075, acc: 1.000000]\n",
      "620: [D loss: 3.782984, acc: 0.500000]  [A loss: 4.677181, acc: 0.000000]\n",
      "621: [D loss: 1.074875, acc: 0.539062]  [A loss: 4.068050, acc: 0.011719]\n",
      "622: [D loss: 1.464406, acc: 0.505859]  [A loss: 8.080670, acc: 0.000000]\n",
      "623: [D loss: 0.921204, acc: 0.580078]  [A loss: 0.262978, acc: 0.875000]\n",
      "624: [D loss: 2.149489, acc: 0.494141]  [A loss: 9.989564, acc: 0.000000]\n",
      "625: [D loss: 1.450009, acc: 0.539062]  [A loss: 0.007725, acc: 1.000000]\n",
      "626: [D loss: 3.580176, acc: 0.500000]  [A loss: 3.631158, acc: 0.015625]\n",
      "627: [D loss: 1.049254, acc: 0.529297]  [A loss: 3.736389, acc: 0.035156]\n",
      "628: [D loss: 1.299135, acc: 0.523438]  [A loss: 6.941458, acc: 0.000000]\n",
      "629: [D loss: 0.985126, acc: 0.544922]  [A loss: 0.676262, acc: 0.625000]\n",
      "630: [D loss: 1.822866, acc: 0.515625]  [A loss: 9.278582, acc: 0.000000]\n",
      "631: [D loss: 1.458282, acc: 0.509766]  [A loss: 0.008062, acc: 1.000000]\n",
      "632: [D loss: 3.725845, acc: 0.500000]  [A loss: 3.310838, acc: 0.050781]\n",
      "633: [D loss: 1.230198, acc: 0.539062]  [A loss: 6.256948, acc: 0.000000]\n",
      "634: [D loss: 1.005163, acc: 0.521484]  [A loss: 1.241199, acc: 0.386719]\n",
      "635: [D loss: 1.776320, acc: 0.515625]  [A loss: 9.279060, acc: 0.000000]\n",
      "636: [D loss: 1.405859, acc: 0.513672]  [A loss: 0.010383, acc: 1.000000]\n",
      "637: [D loss: 3.973028, acc: 0.500000]  [A loss: 5.209040, acc: 0.000000]\n",
      "638: [D loss: 1.155067, acc: 0.552734]  [A loss: 5.691472, acc: 0.000000]\n",
      "639: [D loss: 1.370748, acc: 0.515625]  [A loss: 6.938570, acc: 0.000000]\n",
      "640: [D loss: 1.154473, acc: 0.525391]  [A loss: 3.509359, acc: 0.039062]\n",
      "641: [D loss: 1.849262, acc: 0.496094]  [A loss: 12.746010, acc: 0.000000]\n",
      "642: [D loss: 2.547762, acc: 0.511719]  [A loss: 0.000627, acc: 1.000000]\n",
      "643: [D loss: 5.700550, acc: 0.500000]  [A loss: 1.159467, acc: 0.421875]\n",
      "644: [D loss: 1.973344, acc: 0.523438]  [A loss: 10.177229, acc: 0.000000]\n",
      "645: [D loss: 1.335837, acc: 0.548828]  [A loss: 0.025294, acc: 1.000000]\n",
      "646: [D loss: 3.139348, acc: 0.503906]  [A loss: 6.353792, acc: 0.000000]\n",
      "647: [D loss: 0.863287, acc: 0.583984]  [A loss: 1.273428, acc: 0.367188]\n",
      "648: [D loss: 1.795214, acc: 0.513672]  [A loss: 8.581325, acc: 0.000000]\n",
      "649: [D loss: 1.017086, acc: 0.576172]  [A loss: 0.046489, acc: 1.000000]\n",
      "650: [D loss: 2.525574, acc: 0.505859]  [A loss: 5.590318, acc: 0.000000]\n",
      "651: [D loss: 0.964535, acc: 0.550781]  [A loss: 1.713378, acc: 0.195312]\n",
      "652: [D loss: 1.685837, acc: 0.517578]  [A loss: 8.656838, acc: 0.000000]\n",
      "653: [D loss: 1.181978, acc: 0.562500]  [A loss: 0.016286, acc: 1.000000]\n",
      "654: [D loss: 3.128562, acc: 0.500000]  [A loss: 5.563971, acc: 0.000000]\n",
      "655: [D loss: 0.970797, acc: 0.568359]  [A loss: 2.866462, acc: 0.062500]\n",
      "656: [D loss: 1.466279, acc: 0.509766]  [A loss: 8.133775, acc: 0.000000]\n",
      "657: [D loss: 1.057974, acc: 0.568359]  [A loss: 0.107143, acc: 0.964844]\n",
      "658: [D loss: 2.453878, acc: 0.507812]  [A loss: 7.946631, acc: 0.000000]\n",
      "659: [D loss: 1.202096, acc: 0.556641]  [A loss: 0.023976, acc: 0.996094]\n",
      "660: [D loss: 2.957153, acc: 0.501953]  [A loss: 3.501067, acc: 0.031250]\n",
      "661: [D loss: 1.125202, acc: 0.574219]  [A loss: 4.925866, acc: 0.000000]\n",
      "662: [D loss: 1.034204, acc: 0.558594]  [A loss: 4.478477, acc: 0.003906]\n",
      "663: [D loss: 1.266342, acc: 0.527344]  [A loss: 7.048164, acc: 0.000000]\n",
      "664: [D loss: 1.041716, acc: 0.560547]  [A loss: 0.366446, acc: 0.851562]\n",
      "665: [D loss: 1.935741, acc: 0.496094]  [A loss: 11.350302, acc: 0.000000]\n",
      "666: [D loss: 2.015305, acc: 0.517578]  [A loss: 0.000807, acc: 1.000000]\n",
      "667: [D loss: 5.650272, acc: 0.500000]  [A loss: 1.209324, acc: 0.445312]\n",
      "668: [D loss: 2.085992, acc: 0.527344]  [A loss: 11.200090, acc: 0.000000]\n",
      "669: [D loss: 1.486713, acc: 0.542969]  [A loss: 0.007178, acc: 1.000000]\n",
      "670: [D loss: 4.218860, acc: 0.500000]  [A loss: 3.231922, acc: 0.062500]\n",
      "671: [D loss: 1.854118, acc: 0.537109]  [A loss: 9.226882, acc: 0.000000]\n",
      "672: [D loss: 1.163758, acc: 0.546875]  [A loss: 0.121089, acc: 0.964844]\n",
      "673: [D loss: 2.432289, acc: 0.525391]  [A loss: 9.525641, acc: 0.000000]\n",
      "674: [D loss: 1.212001, acc: 0.578125]  [A loss: 0.033712, acc: 1.000000]\n",
      "675: [D loss: 3.102129, acc: 0.505859]  [A loss: 4.564470, acc: 0.007812]\n",
      "676: [D loss: 1.124184, acc: 0.566406]  [A loss: 4.815131, acc: 0.000000]\n",
      "677: [D loss: 1.324322, acc: 0.541016]  [A loss: 6.359685, acc: 0.000000]\n",
      "678: [D loss: 1.100093, acc: 0.552734]  [A loss: 3.855664, acc: 0.035156]\n",
      "679: [D loss: 1.560649, acc: 0.523438]  [A loss: 9.431818, acc: 0.000000]\n",
      "680: [D loss: 1.166144, acc: 0.562500]  [A loss: 0.032397, acc: 0.996094]\n",
      "681: [D loss: 3.279477, acc: 0.503906]  [A loss: 7.551415, acc: 0.000000]\n",
      "682: [D loss: 1.109779, acc: 0.566406]  [A loss: 0.319383, acc: 0.863281]\n",
      "683: [D loss: 1.858322, acc: 0.511719]  [A loss: 8.969373, acc: 0.000000]\n",
      "684: [D loss: 1.183966, acc: 0.548828]  [A loss: 0.021757, acc: 1.000000]\n",
      "685: [D loss: 3.400595, acc: 0.500000]  [A loss: 5.401156, acc: 0.000000]\n",
      "686: [D loss: 0.955757, acc: 0.607422]  [A loss: 2.566808, acc: 0.101562]\n",
      "687: [D loss: 1.378624, acc: 0.552734]  [A loss: 7.172353, acc: 0.000000]\n",
      "688: [D loss: 0.876934, acc: 0.623047]  [A loss: 0.223164, acc: 0.917969]\n",
      "689: [D loss: 1.955123, acc: 0.521484]  [A loss: 7.965346, acc: 0.000000]\n",
      "690: [D loss: 1.207219, acc: 0.552734]  [A loss: 0.023887, acc: 0.996094]\n",
      "691: [D loss: 3.340962, acc: 0.505859]  [A loss: 5.895456, acc: 0.000000]\n",
      "692: [D loss: 0.883724, acc: 0.605469]  [A loss: 2.231044, acc: 0.164062]\n",
      "693: [D loss: 1.523222, acc: 0.531250]  [A loss: 8.139157, acc: 0.000000]\n",
      "694: [D loss: 1.064495, acc: 0.574219]  [A loss: 0.047445, acc: 0.992188]\n",
      "695: [D loss: 2.808154, acc: 0.509766]  [A loss: 6.844813, acc: 0.000000]\n",
      "696: [D loss: 1.012973, acc: 0.556641]  [A loss: 0.485436, acc: 0.761719]\n",
      "697: [D loss: 1.751715, acc: 0.535156]  [A loss: 6.770204, acc: 0.000000]\n",
      "698: [D loss: 0.877982, acc: 0.628906]  [A loss: 0.154462, acc: 0.945312]\n",
      "699: [D loss: 1.989015, acc: 0.515625]  [A loss: 6.100481, acc: 0.000000]\n",
      "700: [D loss: 0.894987, acc: 0.603516]  [A loss: 0.648122, acc: 0.628906]\n",
      "701: [D loss: 1.552081, acc: 0.517578]  [A loss: 7.646616, acc: 0.000000]\n",
      "702: [D loss: 0.841239, acc: 0.640625]  [A loss: 0.118787, acc: 0.957031]\n",
      "703: [D loss: 2.223248, acc: 0.505859]  [A loss: 7.412448, acc: 0.000000]\n",
      "704: [D loss: 0.973687, acc: 0.597656]  [A loss: 0.065590, acc: 0.992188]\n",
      "705: [D loss: 2.756151, acc: 0.503906]  [A loss: 5.947923, acc: 0.000000]\n",
      "706: [D loss: 0.852555, acc: 0.607422]  [A loss: 1.514612, acc: 0.261719]\n",
      "707: [D loss: 1.829211, acc: 0.533203]  [A loss: 10.143636, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "708: [D loss: 1.425966, acc: 0.531250]  [A loss: 0.006133, acc: 1.000000]\n",
      "709: [D loss: 4.292678, acc: 0.500000]  [A loss: 2.649075, acc: 0.082031]\n",
      "710: [D loss: 1.552880, acc: 0.537109]  [A loss: 8.777474, acc: 0.000000]\n",
      "711: [D loss: 0.993655, acc: 0.574219]  [A loss: 0.129124, acc: 0.980469]\n",
      "712: [D loss: 2.242882, acc: 0.505859]  [A loss: 8.033885, acc: 0.000000]\n",
      "713: [D loss: 1.044977, acc: 0.599609]  [A loss: 0.072758, acc: 0.980469]\n",
      "714: [D loss: 2.609083, acc: 0.507812]  [A loss: 5.898829, acc: 0.000000]\n",
      "715: [D loss: 0.932005, acc: 0.593750]  [A loss: 1.982313, acc: 0.183594]\n",
      "716: [D loss: 1.879750, acc: 0.533203]  [A loss: 10.343012, acc: 0.000000]\n",
      "717: [D loss: 1.486659, acc: 0.542969]  [A loss: 0.009845, acc: 1.000000]\n",
      "718: [D loss: 4.055919, acc: 0.500000]  [A loss: 3.150983, acc: 0.042969]\n",
      "719: [D loss: 1.237454, acc: 0.554688]  [A loss: 5.277231, acc: 0.003906]\n",
      "720: [D loss: 0.984260, acc: 0.572266]  [A loss: 2.992044, acc: 0.062500]\n",
      "721: [D loss: 1.764169, acc: 0.523438]  [A loss: 9.015924, acc: 0.000000]\n",
      "722: [D loss: 1.226743, acc: 0.531250]  [A loss: 0.050755, acc: 0.996094]\n",
      "723: [D loss: 2.912030, acc: 0.498047]  [A loss: 6.149601, acc: 0.000000]\n",
      "724: [D loss: 0.877497, acc: 0.607422]  [A loss: 0.647691, acc: 0.632812]\n",
      "725: [D loss: 1.620576, acc: 0.539062]  [A loss: 6.751298, acc: 0.000000]\n",
      "726: [D loss: 0.972556, acc: 0.582031]  [A loss: 0.265914, acc: 0.882812]\n",
      "727: [D loss: 1.886489, acc: 0.521484]  [A loss: 6.955652, acc: 0.000000]\n",
      "728: [D loss: 0.980251, acc: 0.566406]  [A loss: 0.253011, acc: 0.882812]\n",
      "729: [D loss: 1.984311, acc: 0.501953]  [A loss: 8.220488, acc: 0.000000]\n",
      "730: [D loss: 1.010149, acc: 0.593750]  [A loss: 0.094452, acc: 0.980469]\n",
      "731: [D loss: 2.404452, acc: 0.509766]  [A loss: 7.552906, acc: 0.000000]\n",
      "732: [D loss: 0.976345, acc: 0.607422]  [A loss: 0.107199, acc: 0.976562]\n",
      "733: [D loss: 2.465706, acc: 0.507812]  [A loss: 6.663246, acc: 0.000000]\n",
      "734: [D loss: 0.768880, acc: 0.642578]  [A loss: 0.545476, acc: 0.703125]\n",
      "735: [D loss: 1.604700, acc: 0.517578]  [A loss: 6.899051, acc: 0.000000]\n",
      "736: [D loss: 0.886880, acc: 0.587891]  [A loss: 0.205704, acc: 0.921875]\n",
      "737: [D loss: 2.127064, acc: 0.507812]  [A loss: 7.457493, acc: 0.000000]\n",
      "738: [D loss: 0.830497, acc: 0.652344]  [A loss: 0.155455, acc: 0.953125]\n",
      "739: [D loss: 2.111037, acc: 0.509766]  [A loss: 7.120729, acc: 0.000000]\n",
      "740: [D loss: 0.923243, acc: 0.619141]  [A loss: 0.178149, acc: 0.937500]\n",
      "741: [D loss: 1.973227, acc: 0.519531]  [A loss: 7.139759, acc: 0.000000]\n",
      "742: [D loss: 0.905181, acc: 0.597656]  [A loss: 0.324971, acc: 0.835938]\n",
      "743: [D loss: 1.843814, acc: 0.515625]  [A loss: 7.389338, acc: 0.000000]\n",
      "744: [D loss: 0.782636, acc: 0.671875]  [A loss: 0.275340, acc: 0.878906]\n",
      "745: [D loss: 1.900592, acc: 0.523438]  [A loss: 7.908484, acc: 0.000000]\n",
      "746: [D loss: 0.865552, acc: 0.632812]  [A loss: 0.093732, acc: 0.964844]\n",
      "747: [D loss: 2.501366, acc: 0.503906]  [A loss: 6.224983, acc: 0.003906]\n",
      "748: [D loss: 0.907408, acc: 0.619141]  [A loss: 2.695835, acc: 0.085938]\n",
      "749: [D loss: 2.013344, acc: 0.533203]  [A loss: 12.423087, acc: 0.000000]\n",
      "750: [D loss: 2.334487, acc: 0.525391]  [A loss: 0.000649, acc: 1.000000]\n",
      "751: [D loss: 6.393581, acc: 0.500000]  [A loss: 0.270358, acc: 0.878906]\n",
      "752: [D loss: 2.730376, acc: 0.519531]  [A loss: 10.244522, acc: 0.000000]\n",
      "753: [D loss: 0.983097, acc: 0.621094]  [A loss: 0.220878, acc: 0.886719]\n",
      "754: [D loss: 2.274092, acc: 0.507812]  [A loss: 8.008211, acc: 0.000000]\n",
      "755: [D loss: 1.041716, acc: 0.601562]  [A loss: 2.660828, acc: 0.093750]\n",
      "756: [D loss: 2.097541, acc: 0.533203]  [A loss: 10.767071, acc: 0.000000]\n",
      "757: [D loss: 1.426023, acc: 0.558594]  [A loss: 0.032280, acc: 0.992188]\n",
      "758: [D loss: 3.939477, acc: 0.501953]  [A loss: 5.020739, acc: 0.023438]\n",
      "759: [D loss: 1.520381, acc: 0.595703]  [A loss: 7.671394, acc: 0.003906]\n",
      "760: [D loss: 1.122088, acc: 0.560547]  [A loss: 1.387929, acc: 0.363281]\n",
      "761: [D loss: 2.276802, acc: 0.541016]  [A loss: 11.294416, acc: 0.000000]\n",
      "762: [D loss: 2.086845, acc: 0.515625]  [A loss: 0.014599, acc: 1.000000]\n",
      "763: [D loss: 5.155988, acc: 0.500000]  [A loss: 0.820459, acc: 0.578125]\n",
      "764: [D loss: 1.997897, acc: 0.531250]  [A loss: 7.086810, acc: 0.000000]\n",
      "765: [D loss: 1.249270, acc: 0.527344]  [A loss: 3.301569, acc: 0.085938]\n",
      "766: [D loss: 2.314950, acc: 0.531250]  [A loss: 9.899914, acc: 0.000000]\n",
      "767: [D loss: 1.473532, acc: 0.527344]  [A loss: 0.051081, acc: 0.988281]\n",
      "768: [D loss: 4.202312, acc: 0.503906]  [A loss: 4.494678, acc: 0.019531]\n",
      "769: [D loss: 1.383027, acc: 0.546875]  [A loss: 5.619552, acc: 0.000000]\n",
      "770: [D loss: 1.247209, acc: 0.529297]  [A loss: 4.235218, acc: 0.019531]\n",
      "771: [D loss: 1.774223, acc: 0.523438]  [A loss: 9.835659, acc: 0.000000]\n",
      "772: [D loss: 1.401608, acc: 0.527344]  [A loss: 0.070412, acc: 0.980469]\n",
      "773: [D loss: 3.832772, acc: 0.503906]  [A loss: 6.288048, acc: 0.000000]\n",
      "774: [D loss: 1.058989, acc: 0.552734]  [A loss: 1.884232, acc: 0.222656]\n",
      "775: [D loss: 2.030057, acc: 0.507812]  [A loss: 10.099863, acc: 0.000000]\n",
      "776: [D loss: 1.929045, acc: 0.507812]  [A loss: 0.042422, acc: 0.988281]\n",
      "777: [D loss: 4.166544, acc: 0.503906]  [A loss: 2.632540, acc: 0.121094]\n",
      "778: [D loss: 1.840668, acc: 0.556641]  [A loss: 7.488731, acc: 0.000000]\n",
      "779: [D loss: 1.047389, acc: 0.578125]  [A loss: 0.379522, acc: 0.800781]\n",
      "780: [D loss: 2.103990, acc: 0.527344]  [A loss: 7.551983, acc: 0.000000]\n",
      "781: [D loss: 1.197937, acc: 0.525391]  [A loss: 0.158247, acc: 0.964844]\n",
      "782: [D loss: 2.693505, acc: 0.511719]  [A loss: 5.585671, acc: 0.000000]\n",
      "783: [D loss: 0.970804, acc: 0.568359]  [A loss: 1.071482, acc: 0.398438]\n",
      "784: [D loss: 1.701520, acc: 0.517578]  [A loss: 6.611220, acc: 0.000000]\n",
      "785: [D loss: 1.094871, acc: 0.517578]  [A loss: 0.350251, acc: 0.816406]\n",
      "786: [D loss: 1.992707, acc: 0.517578]  [A loss: 7.488339, acc: 0.000000]\n",
      "787: [D loss: 1.035364, acc: 0.556641]  [A loss: 0.263768, acc: 0.871094]\n",
      "788: [D loss: 1.870068, acc: 0.525391]  [A loss: 6.182278, acc: 0.000000]\n",
      "789: [D loss: 0.903921, acc: 0.599609]  [A loss: 0.870395, acc: 0.546875]\n",
      "790: [D loss: 1.719883, acc: 0.541016]  [A loss: 7.363895, acc: 0.000000]\n",
      "791: [D loss: 0.988757, acc: 0.589844]  [A loss: 0.156910, acc: 0.953125]\n",
      "792: [D loss: 2.139605, acc: 0.517578]  [A loss: 6.523233, acc: 0.000000]\n",
      "793: [D loss: 0.990335, acc: 0.568359]  [A loss: 1.099362, acc: 0.375000]\n",
      "794: [D loss: 1.830851, acc: 0.542969]  [A loss: 9.969810, acc: 0.000000]\n",
      "795: [D loss: 1.468979, acc: 0.507812]  [A loss: 0.010607, acc: 1.000000]\n",
      "796: [D loss: 4.617714, acc: 0.500000]  [A loss: 3.047540, acc: 0.093750]\n",
      "797: [D loss: 1.973134, acc: 0.519531]  [A loss: 9.990005, acc: 0.000000]\n",
      "798: [D loss: 1.313674, acc: 0.597656]  [A loss: 0.021494, acc: 1.000000]\n",
      "799: [D loss: 3.573732, acc: 0.500000]  [A loss: 4.472462, acc: 0.011719]\n",
      "800: [D loss: 1.509693, acc: 0.552734]  [A loss: 7.772202, acc: 0.000000]\n",
      "801: [D loss: 1.092065, acc: 0.529297]  [A loss: 0.579532, acc: 0.675781]\n",
      "802: [D loss: 2.024097, acc: 0.541016]  [A loss: 9.713531, acc: 0.000000]\n",
      "803: [D loss: 1.435905, acc: 0.537109]  [A loss: 0.029371, acc: 0.996094]\n",
      "804: [D loss: 3.540762, acc: 0.501953]  [A loss: 3.988789, acc: 0.015625]\n",
      "805: [D loss: 1.535025, acc: 0.585938]  [A loss: 7.677390, acc: 0.000000]\n",
      "806: [D loss: 0.838034, acc: 0.621094]  [A loss: 0.349404, acc: 0.816406]\n",
      "807: [D loss: 1.851515, acc: 0.525391]  [A loss: 8.081432, acc: 0.000000]\n",
      "808: [D loss: 1.067927, acc: 0.578125]  [A loss: 0.159890, acc: 0.941406]\n",
      "809: [D loss: 2.162779, acc: 0.531250]  [A loss: 7.026228, acc: 0.000000]\n",
      "810: [D loss: 1.000591, acc: 0.595703]  [A loss: 0.945004, acc: 0.476562]\n",
      "811: [D loss: 1.779875, acc: 0.552734]  [A loss: 8.980524, acc: 0.000000]\n",
      "812: [D loss: 1.167154, acc: 0.589844]  [A loss: 0.037995, acc: 1.000000]\n",
      "813: [D loss: 3.222955, acc: 0.507812]  [A loss: 3.807108, acc: 0.019531]\n",
      "814: [D loss: 1.132365, acc: 0.597656]  [A loss: 5.631358, acc: 0.003906]\n",
      "815: [D loss: 1.068763, acc: 0.589844]  [A loss: 3.740648, acc: 0.015625]\n",
      "816: [D loss: 1.724629, acc: 0.531250]  [A loss: 10.494061, acc: 0.000000]\n",
      "817: [D loss: 1.872199, acc: 0.515625]  [A loss: 0.008347, acc: 1.000000]\n",
      "818: [D loss: 5.048168, acc: 0.500000]  [A loss: 2.017829, acc: 0.234375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "819: [D loss: 2.326306, acc: 0.527344]  [A loss: 11.147060, acc: 0.000000]\n",
      "820: [D loss: 1.855155, acc: 0.531250]  [A loss: 0.013173, acc: 1.000000]\n",
      "821: [D loss: 4.532968, acc: 0.500000]  [A loss: 2.085907, acc: 0.226562]\n",
      "822: [D loss: 1.890219, acc: 0.562500]  [A loss: 8.575846, acc: 0.000000]\n",
      "823: [D loss: 1.193246, acc: 0.560547]  [A loss: 0.132038, acc: 0.945312]\n",
      "824: [D loss: 2.786444, acc: 0.505859]  [A loss: 6.254716, acc: 0.000000]\n",
      "825: [D loss: 0.958779, acc: 0.587891]  [A loss: 1.381450, acc: 0.347656]\n",
      "826: [D loss: 1.865381, acc: 0.535156]  [A loss: 7.554563, acc: 0.000000]\n",
      "827: [D loss: 1.142860, acc: 0.535156]  [A loss: 0.323638, acc: 0.839844]\n",
      "828: [D loss: 2.258297, acc: 0.521484]  [A loss: 7.717062, acc: 0.000000]\n",
      "829: [D loss: 0.982936, acc: 0.576172]  [A loss: 0.289197, acc: 0.855469]\n",
      "830: [D loss: 1.973074, acc: 0.523438]  [A loss: 6.615812, acc: 0.000000]\n",
      "831: [D loss: 0.943112, acc: 0.599609]  [A loss: 0.793180, acc: 0.566406]\n",
      "832: [D loss: 1.713440, acc: 0.542969]  [A loss: 7.345413, acc: 0.000000]\n",
      "833: [D loss: 0.901792, acc: 0.580078]  [A loss: 0.327775, acc: 0.847656]\n",
      "834: [D loss: 2.042012, acc: 0.519531]  [A loss: 8.599473, acc: 0.000000]\n",
      "835: [D loss: 1.188406, acc: 0.589844]  [A loss: 0.037108, acc: 1.000000]\n",
      "836: [D loss: 2.789408, acc: 0.503906]  [A loss: 4.484273, acc: 0.011719]\n",
      "837: [D loss: 1.069631, acc: 0.593750]  [A loss: 4.462891, acc: 0.000000]\n",
      "838: [D loss: 1.246557, acc: 0.562500]  [A loss: 6.115470, acc: 0.000000]\n",
      "839: [D loss: 1.045260, acc: 0.593750]  [A loss: 4.322452, acc: 0.019531]\n",
      "840: [D loss: 1.452404, acc: 0.564453]  [A loss: 9.612354, acc: 0.000000]\n",
      "841: [D loss: 1.526187, acc: 0.521484]  [A loss: 0.006891, acc: 1.000000]\n",
      "842: [D loss: 5.095686, acc: 0.500000]  [A loss: 1.553903, acc: 0.281250]\n",
      "843: [D loss: 1.771809, acc: 0.558594]  [A loss: 9.035298, acc: 0.000000]\n",
      "844: [D loss: 1.315847, acc: 0.566406]  [A loss: 0.033233, acc: 1.000000]\n",
      "845: [D loss: 3.735152, acc: 0.500000]  [A loss: 5.408895, acc: 0.000000]\n",
      "846: [D loss: 1.062329, acc: 0.591797]  [A loss: 3.724101, acc: 0.031250]\n",
      "847: [D loss: 1.667768, acc: 0.558594]  [A loss: 10.422933, acc: 0.000000]\n",
      "848: [D loss: 1.970914, acc: 0.515625]  [A loss: 0.007006, acc: 1.000000]\n",
      "849: [D loss: 4.851647, acc: 0.500000]  [A loss: 0.651152, acc: 0.605469]\n",
      "850: [D loss: 1.740080, acc: 0.539062]  [A loss: 6.281783, acc: 0.000000]\n",
      "851: [D loss: 1.071378, acc: 0.576172]  [A loss: 2.938377, acc: 0.062500]\n",
      "852: [D loss: 1.625240, acc: 0.558594]  [A loss: 8.025674, acc: 0.000000]\n",
      "853: [D loss: 1.066643, acc: 0.560547]  [A loss: 0.094087, acc: 0.972656]\n",
      "854: [D loss: 2.890372, acc: 0.507812]  [A loss: 5.499676, acc: 0.003906]\n",
      "855: [D loss: 1.057922, acc: 0.605469]  [A loss: 3.336678, acc: 0.042969]\n",
      "856: [D loss: 1.553120, acc: 0.576172]  [A loss: 8.778019, acc: 0.000000]\n",
      "857: [D loss: 1.245137, acc: 0.572266]  [A loss: 0.031367, acc: 1.000000]\n",
      "858: [D loss: 3.841242, acc: 0.500000]  [A loss: 2.665216, acc: 0.074219]\n",
      "859: [D loss: 1.513691, acc: 0.597656]  [A loss: 7.290899, acc: 0.000000]\n",
      "860: [D loss: 0.962191, acc: 0.613281]  [A loss: 0.282927, acc: 0.863281]\n",
      "861: [D loss: 2.191280, acc: 0.533203]  [A loss: 7.746964, acc: 0.000000]\n",
      "862: [D loss: 1.199532, acc: 0.544922]  [A loss: 0.054491, acc: 1.000000]\n",
      "863: [D loss: 3.310408, acc: 0.500000]  [A loss: 2.675746, acc: 0.058594]\n",
      "864: [D loss: 1.484049, acc: 0.574219]  [A loss: 6.007340, acc: 0.000000]\n",
      "865: [D loss: 0.905376, acc: 0.603516]  [A loss: 0.735277, acc: 0.546875]\n",
      "866: [D loss: 1.628907, acc: 0.566406]  [A loss: 6.818748, acc: 0.000000]\n",
      "867: [D loss: 1.002506, acc: 0.599609]  [A loss: 0.403582, acc: 0.773438]\n",
      "868: [D loss: 1.869197, acc: 0.529297]  [A loss: 7.548186, acc: 0.000000]\n",
      "869: [D loss: 1.041238, acc: 0.587891]  [A loss: 0.157871, acc: 0.937500]\n",
      "870: [D loss: 2.572288, acc: 0.511719]  [A loss: 7.287726, acc: 0.000000]\n",
      "871: [D loss: 1.099398, acc: 0.578125]  [A loss: 0.072353, acc: 0.984375]\n",
      "872: [D loss: 3.121241, acc: 0.500000]  [A loss: 3.446049, acc: 0.027344]\n",
      "873: [D loss: 1.144648, acc: 0.597656]  [A loss: 4.500765, acc: 0.015625]\n",
      "874: [D loss: 0.894315, acc: 0.634766]  [A loss: 2.999389, acc: 0.039062]\n",
      "875: [D loss: 1.333680, acc: 0.583984]  [A loss: 7.038241, acc: 0.000000]\n",
      "876: [D loss: 1.007687, acc: 0.583984]  [A loss: 0.414630, acc: 0.757812]\n",
      "877: [D loss: 2.003778, acc: 0.531250]  [A loss: 9.765360, acc: 0.000000]\n",
      "878: [D loss: 1.564231, acc: 0.535156]  [A loss: 0.011857, acc: 1.000000]\n",
      "879: [D loss: 4.955382, acc: 0.500000]  [A loss: 1.564463, acc: 0.328125]\n",
      "880: [D loss: 2.010994, acc: 0.570312]  [A loss: 9.820173, acc: 0.000000]\n",
      "881: [D loss: 1.104370, acc: 0.601562]  [A loss: 0.079528, acc: 0.992188]\n",
      "882: [D loss: 2.960433, acc: 0.503906]  [A loss: 6.407783, acc: 0.000000]\n",
      "883: [D loss: 0.968351, acc: 0.640625]  [A loss: 3.243023, acc: 0.089844]\n",
      "884: [D loss: 1.595644, acc: 0.593750]  [A loss: 9.340605, acc: 0.000000]\n",
      "885: [D loss: 1.332122, acc: 0.576172]  [A loss: 0.030704, acc: 1.000000]\n",
      "886: [D loss: 3.606555, acc: 0.500000]  [A loss: 2.535732, acc: 0.089844]\n",
      "887: [D loss: 1.552549, acc: 0.589844]  [A loss: 8.051529, acc: 0.000000]\n",
      "888: [D loss: 1.022409, acc: 0.628906]  [A loss: 0.155862, acc: 0.925781]\n",
      "889: [D loss: 2.721601, acc: 0.509766]  [A loss: 6.397548, acc: 0.000000]\n",
      "890: [D loss: 0.958739, acc: 0.619141]  [A loss: 1.646380, acc: 0.230469]\n",
      "891: [D loss: 1.727799, acc: 0.583984]  [A loss: 8.671459, acc: 0.000000]\n",
      "892: [D loss: 1.217022, acc: 0.568359]  [A loss: 0.130717, acc: 0.968750]\n",
      "893: [D loss: 2.654183, acc: 0.505859]  [A loss: 4.852559, acc: 0.011719]\n",
      "894: [D loss: 1.002527, acc: 0.630859]  [A loss: 3.196101, acc: 0.054688]\n",
      "895: [D loss: 1.932569, acc: 0.552734]  [A loss: 10.282021, acc: 0.000000]\n",
      "896: [D loss: 2.289963, acc: 0.509766]  [A loss: 0.018764, acc: 0.996094]\n",
      "897: [D loss: 4.760342, acc: 0.500000]  [A loss: 0.427814, acc: 0.746094]\n",
      "898: [D loss: 2.041327, acc: 0.552734]  [A loss: 5.576898, acc: 0.000000]\n",
      "899: [D loss: 0.968224, acc: 0.632812]  [A loss: 2.025754, acc: 0.144531]\n",
      "900: [D loss: 1.629874, acc: 0.556641]  [A loss: 7.067746, acc: 0.000000]\n",
      "901: [D loss: 0.987583, acc: 0.609375]  [A loss: 1.354913, acc: 0.308594]\n",
      "902: [D loss: 1.959703, acc: 0.552734]  [A loss: 9.108426, acc: 0.000000]\n",
      "903: [D loss: 1.317001, acc: 0.554688]  [A loss: 0.043551, acc: 1.000000]\n",
      "904: [D loss: 3.518451, acc: 0.498047]  [A loss: 4.294047, acc: 0.015625]\n",
      "905: [D loss: 1.163796, acc: 0.615234]  [A loss: 4.981081, acc: 0.003906]\n",
      "906: [D loss: 1.214885, acc: 0.578125]  [A loss: 4.033945, acc: 0.011719]\n",
      "907: [D loss: 1.573618, acc: 0.582031]  [A loss: 8.521070, acc: 0.000000]\n",
      "908: [D loss: 1.180195, acc: 0.580078]  [A loss: 0.066673, acc: 0.988281]\n",
      "909: [D loss: 3.749484, acc: 0.505859]  [A loss: 4.721012, acc: 0.011719]\n",
      "910: [D loss: 1.114301, acc: 0.615234]  [A loss: 4.944449, acc: 0.003906]\n",
      "911: [D loss: 1.284861, acc: 0.554688]  [A loss: 5.856234, acc: 0.003906]\n",
      "912: [D loss: 0.988296, acc: 0.613281]  [A loss: 2.295330, acc: 0.164062]\n",
      "913: [D loss: 2.028641, acc: 0.566406]  [A loss: 11.432291, acc: 0.000000]\n",
      "914: [D loss: 4.266415, acc: 0.500000]  [A loss: 0.060896, acc: 0.992188]\n",
      "915: [D loss: 4.105784, acc: 0.500000]  [A loss: 0.745705, acc: 0.550781]\n",
      "916: [D loss: 1.616658, acc: 0.583984]  [A loss: 5.784484, acc: 0.000000]\n",
      "917: [D loss: 1.049036, acc: 0.625000]  [A loss: 2.110409, acc: 0.109375]\n",
      "918: [D loss: 1.992116, acc: 0.550781]  [A loss: 9.685061, acc: 0.000000]\n",
      "919: [D loss: 1.766393, acc: 0.529297]  [A loss: 0.042680, acc: 1.000000]\n",
      "920: [D loss: 3.822738, acc: 0.500000]  [A loss: 1.130854, acc: 0.375000]\n",
      "921: [D loss: 1.418588, acc: 0.605469]  [A loss: 4.256901, acc: 0.007812]\n",
      "922: [D loss: 1.145193, acc: 0.582031]  [A loss: 3.582902, acc: 0.023438]\n",
      "923: [D loss: 1.495557, acc: 0.576172]  [A loss: 6.860774, acc: 0.000000]\n",
      "924: [D loss: 1.134029, acc: 0.544922]  [A loss: 0.258269, acc: 0.871094]\n",
      "925: [D loss: 2.155023, acc: 0.525391]  [A loss: 5.464823, acc: 0.000000]\n",
      "926: [D loss: 0.808364, acc: 0.675781]  [A loss: 1.442796, acc: 0.273438]\n",
      "927: [D loss: 1.530026, acc: 0.580078]  [A loss: 6.425641, acc: 0.000000]\n",
      "928: [D loss: 0.968452, acc: 0.601562]  [A loss: 0.349435, acc: 0.781250]\n",
      "929: [D loss: 1.847855, acc: 0.546875]  [A loss: 6.332510, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "930: [D loss: 1.036324, acc: 0.564453]  [A loss: 0.448800, acc: 0.726562]\n",
      "931: [D loss: 1.985589, acc: 0.552734]  [A loss: 6.479195, acc: 0.000000]\n",
      "932: [D loss: 0.896530, acc: 0.607422]  [A loss: 0.285927, acc: 0.851562]\n",
      "933: [D loss: 1.808544, acc: 0.529297]  [A loss: 4.876399, acc: 0.000000]\n",
      "934: [D loss: 0.891609, acc: 0.609375]  [A loss: 1.812593, acc: 0.191406]\n",
      "935: [D loss: 1.524228, acc: 0.582031]  [A loss: 7.740957, acc: 0.000000]\n",
      "936: [D loss: 1.108836, acc: 0.560547]  [A loss: 0.095227, acc: 0.992188]\n",
      "937: [D loss: 2.737018, acc: 0.503906]  [A loss: 4.873147, acc: 0.000000]\n",
      "938: [D loss: 0.989916, acc: 0.623047]  [A loss: 3.032412, acc: 0.042969]\n",
      "939: [D loss: 1.382207, acc: 0.580078]  [A loss: 7.181217, acc: 0.000000]\n",
      "940: [D loss: 1.124617, acc: 0.552734]  [A loss: 0.156713, acc: 0.957031]\n",
      "941: [D loss: 2.683642, acc: 0.507812]  [A loss: 6.023719, acc: 0.000000]\n",
      "942: [D loss: 0.953864, acc: 0.587891]  [A loss: 0.315940, acc: 0.859375]\n",
      "943: [D loss: 1.898682, acc: 0.541016]  [A loss: 6.108029, acc: 0.000000]\n",
      "944: [D loss: 0.925504, acc: 0.595703]  [A loss: 0.682491, acc: 0.554688]\n",
      "945: [D loss: 1.511035, acc: 0.578125]  [A loss: 6.141800, acc: 0.000000]\n",
      "946: [D loss: 0.865425, acc: 0.621094]  [A loss: 0.270182, acc: 0.882812]\n",
      "947: [D loss: 1.953901, acc: 0.529297]  [A loss: 7.423104, acc: 0.000000]\n",
      "948: [D loss: 0.994225, acc: 0.601562]  [A loss: 0.126847, acc: 0.972656]\n",
      "949: [D loss: 2.330126, acc: 0.507812]  [A loss: 5.357368, acc: 0.000000]\n",
      "950: [D loss: 0.926984, acc: 0.666016]  [A loss: 2.261289, acc: 0.117188]\n",
      "951: [D loss: 1.508174, acc: 0.568359]  [A loss: 9.176554, acc: 0.000000]\n",
      "952: [D loss: 1.192076, acc: 0.554688]  [A loss: 0.020856, acc: 1.000000]\n",
      "953: [D loss: 3.956110, acc: 0.500000]  [A loss: 1.423540, acc: 0.292969]\n",
      "954: [D loss: 1.291422, acc: 0.623047]  [A loss: 5.755876, acc: 0.000000]\n",
      "955: [D loss: 0.902552, acc: 0.648438]  [A loss: 0.984908, acc: 0.410156]\n",
      "956: [D loss: 1.460325, acc: 0.583984]  [A loss: 6.946014, acc: 0.000000]\n",
      "957: [D loss: 0.835230, acc: 0.636719]  [A loss: 0.176207, acc: 0.949219]\n",
      "958: [D loss: 1.894546, acc: 0.527344]  [A loss: 4.919151, acc: 0.000000]\n",
      "959: [D loss: 0.665138, acc: 0.716797]  [A loss: 1.071043, acc: 0.425781]\n",
      "960: [D loss: 1.360941, acc: 0.599609]  [A loss: 6.511394, acc: 0.000000]\n",
      "961: [D loss: 0.872938, acc: 0.605469]  [A loss: 0.217487, acc: 0.914062]\n",
      "962: [D loss: 2.034733, acc: 0.517578]  [A loss: 6.871289, acc: 0.000000]\n",
      "963: [D loss: 0.964371, acc: 0.574219]  [A loss: 0.143127, acc: 0.968750]\n",
      "964: [D loss: 2.465760, acc: 0.501953]  [A loss: 6.553245, acc: 0.000000]\n",
      "965: [D loss: 0.865018, acc: 0.630859]  [A loss: 0.264383, acc: 0.875000]\n",
      "966: [D loss: 1.769132, acc: 0.544922]  [A loss: 5.798531, acc: 0.000000]\n",
      "967: [D loss: 0.884052, acc: 0.634766]  [A loss: 0.467677, acc: 0.730469]\n",
      "968: [D loss: 1.573461, acc: 0.537109]  [A loss: 6.787661, acc: 0.000000]\n",
      "969: [D loss: 0.831780, acc: 0.636719]  [A loss: 0.158793, acc: 0.953125]\n",
      "970: [D loss: 2.016601, acc: 0.513672]  [A loss: 4.999916, acc: 0.000000]\n",
      "971: [D loss: 0.760866, acc: 0.673828]  [A loss: 0.809394, acc: 0.515625]\n",
      "972: [D loss: 1.484223, acc: 0.537109]  [A loss: 6.788619, acc: 0.000000]\n",
      "973: [D loss: 0.986911, acc: 0.552734]  [A loss: 0.101459, acc: 0.988281]\n",
      "974: [D loss: 2.430397, acc: 0.501953]  [A loss: 5.306789, acc: 0.000000]\n",
      "975: [D loss: 0.758790, acc: 0.623047]  [A loss: 0.916139, acc: 0.421875]\n",
      "976: [D loss: 1.367358, acc: 0.550781]  [A loss: 6.164607, acc: 0.000000]\n",
      "977: [D loss: 0.878240, acc: 0.591797]  [A loss: 0.549961, acc: 0.660156]\n",
      "978: [D loss: 1.429552, acc: 0.546875]  [A loss: 6.927014, acc: 0.000000]\n",
      "979: [D loss: 0.985672, acc: 0.570312]  [A loss: 0.133663, acc: 0.964844]\n",
      "980: [D loss: 2.122108, acc: 0.505859]  [A loss: 5.848461, acc: 0.003906]\n",
      "981: [D loss: 0.874402, acc: 0.623047]  [A loss: 0.361159, acc: 0.828125]\n",
      "982: [D loss: 1.634714, acc: 0.531250]  [A loss: 6.850033, acc: 0.000000]\n",
      "983: [D loss: 1.006739, acc: 0.582031]  [A loss: 0.121251, acc: 0.972656]\n",
      "984: [D loss: 2.070648, acc: 0.507812]  [A loss: 5.625077, acc: 0.000000]\n",
      "985: [D loss: 0.850981, acc: 0.621094]  [A loss: 1.879593, acc: 0.140625]\n",
      "986: [D loss: 1.647578, acc: 0.556641]  [A loss: 9.545734, acc: 0.000000]\n",
      "987: [D loss: 1.368098, acc: 0.535156]  [A loss: 0.012693, acc: 1.000000]\n",
      "988: [D loss: 4.330532, acc: 0.500000]  [A loss: 3.114557, acc: 0.023438]\n",
      "989: [D loss: 1.413461, acc: 0.587891]  [A loss: 8.099855, acc: 0.000000]\n",
      "990: [D loss: 1.039905, acc: 0.591797]  [A loss: 0.150824, acc: 0.957031]\n",
      "991: [D loss: 2.429331, acc: 0.509766]  [A loss: 8.637628, acc: 0.000000]\n",
      "992: [D loss: 1.070275, acc: 0.566406]  [A loss: 0.120041, acc: 0.968750]\n",
      "993: [D loss: 2.477866, acc: 0.500000]  [A loss: 6.857222, acc: 0.000000]\n",
      "994: [D loss: 0.918075, acc: 0.595703]  [A loss: 0.153772, acc: 0.964844]\n",
      "995: [D loss: 2.152503, acc: 0.507812]  [A loss: 5.854279, acc: 0.000000]\n",
      "996: [D loss: 0.881266, acc: 0.621094]  [A loss: 0.867634, acc: 0.507812]\n",
      "997: [D loss: 1.716596, acc: 0.513672]  [A loss: 8.272243, acc: 0.000000]\n",
      "998: [D loss: 1.038263, acc: 0.613281]  [A loss: 0.090433, acc: 0.972656]\n",
      "999: [D loss: 2.622502, acc: 0.501953]  [A loss: 6.459830, acc: 0.000000]\n",
      "1000: [D loss: 0.783569, acc: 0.646484]  [A loss: 0.640599, acc: 0.625000]\n",
      "1001: [D loss: 1.478636, acc: 0.550781]  [A loss: 7.877031, acc: 0.000000]\n",
      "1002: [D loss: 0.822559, acc: 0.646484]  [A loss: 0.317704, acc: 0.835938]\n",
      "1003: [D loss: 1.957830, acc: 0.523438]  [A loss: 7.863189, acc: 0.000000]\n",
      "1004: [D loss: 0.951462, acc: 0.611328]  [A loss: 0.078701, acc: 0.980469]\n",
      "1005: [D loss: 2.688569, acc: 0.503906]  [A loss: 5.401869, acc: 0.003906]\n",
      "1006: [D loss: 0.845744, acc: 0.652344]  [A loss: 1.985242, acc: 0.144531]\n",
      "1007: [D loss: 1.293822, acc: 0.585938]  [A loss: 6.913513, acc: 0.000000]\n",
      "1008: [D loss: 0.951714, acc: 0.587891]  [A loss: 0.590615, acc: 0.648438]\n",
      "1009: [D loss: 1.709396, acc: 0.533203]  [A loss: 8.500345, acc: 0.000000]\n",
      "1010: [D loss: 1.154480, acc: 0.572266]  [A loss: 0.023239, acc: 1.000000]\n",
      "1011: [D loss: 3.549470, acc: 0.500000]  [A loss: 3.968500, acc: 0.003906]\n",
      "1012: [D loss: 0.917554, acc: 0.640625]  [A loss: 4.114228, acc: 0.007812]\n",
      "1013: [D loss: 1.063253, acc: 0.607422]  [A loss: 5.888509, acc: 0.003906]\n",
      "1014: [D loss: 0.994498, acc: 0.574219]  [A loss: 2.556365, acc: 0.089844]\n",
      "1015: [D loss: 1.650375, acc: 0.570312]  [A loss: 11.168074, acc: 0.000000]\n",
      "1016: [D loss: 2.255647, acc: 0.513672]  [A loss: 0.008111, acc: 1.000000]\n",
      "1017: [D loss: 5.198131, acc: 0.500000]  [A loss: 0.602048, acc: 0.656250]\n",
      "1018: [D loss: 1.926225, acc: 0.539062]  [A loss: 7.355468, acc: 0.000000]\n",
      "1019: [D loss: 0.954705, acc: 0.597656]  [A loss: 0.432256, acc: 0.765625]\n",
      "1020: [D loss: 1.970578, acc: 0.541016]  [A loss: 6.980524, acc: 0.000000]\n",
      "1021: [D loss: 0.933002, acc: 0.593750]  [A loss: 0.378163, acc: 0.777344]\n",
      "1022: [D loss: 1.948541, acc: 0.529297]  [A loss: 7.127671, acc: 0.000000]\n",
      "1023: [D loss: 1.031337, acc: 0.572266]  [A loss: 0.151794, acc: 0.957031]\n",
      "1024: [D loss: 2.246770, acc: 0.507812]  [A loss: 5.186503, acc: 0.003906]\n",
      "1025: [D loss: 1.092144, acc: 0.597656]  [A loss: 3.662444, acc: 0.015625]\n",
      "1026: [D loss: 1.392985, acc: 0.566406]  [A loss: 7.853937, acc: 0.000000]\n",
      "1027: [D loss: 0.974636, acc: 0.593750]  [A loss: 0.348922, acc: 0.843750]\n",
      "1028: [D loss: 2.032115, acc: 0.537109]  [A loss: 8.697325, acc: 0.000000]\n",
      "1029: [D loss: 1.203353, acc: 0.585938]  [A loss: 0.024799, acc: 1.000000]\n",
      "1030: [D loss: 3.448941, acc: 0.500000]  [A loss: 3.583081, acc: 0.031250]\n",
      "1031: [D loss: 1.205310, acc: 0.566406]  [A loss: 5.406607, acc: 0.000000]\n",
      "1032: [D loss: 0.862637, acc: 0.625000]  [A loss: 1.715359, acc: 0.222656]\n",
      "1033: [D loss: 1.667129, acc: 0.537109]  [A loss: 9.215023, acc: 0.000000]\n",
      "1034: [D loss: 1.110096, acc: 0.585938]  [A loss: 0.027017, acc: 0.992188]\n",
      "1035: [D loss: 3.630997, acc: 0.500000]  [A loss: 4.796422, acc: 0.003906]\n",
      "1036: [D loss: 1.248240, acc: 0.591797]  [A loss: 6.273298, acc: 0.000000]\n",
      "1037: [D loss: 0.996163, acc: 0.564453]  [A loss: 0.615567, acc: 0.660156]\n",
      "1038: [D loss: 1.705225, acc: 0.548828]  [A loss: 7.588543, acc: 0.000000]\n",
      "1039: [D loss: 1.054967, acc: 0.566406]  [A loss: 0.091354, acc: 0.988281]\n",
      "1040: [D loss: 2.630862, acc: 0.505859]  [A loss: 7.254673, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1041: [D loss: 0.916361, acc: 0.603516]  [A loss: 0.198753, acc: 0.917969]\n",
      "1042: [D loss: 2.038127, acc: 0.513672]  [A loss: 6.850323, acc: 0.000000]\n",
      "1043: [D loss: 0.934400, acc: 0.597656]  [A loss: 0.804969, acc: 0.554688]\n",
      "1044: [D loss: 1.765260, acc: 0.525391]  [A loss: 8.706205, acc: 0.000000]\n",
      "1045: [D loss: 1.262280, acc: 0.541016]  [A loss: 0.013284, acc: 1.000000]\n",
      "1046: [D loss: 3.870612, acc: 0.500000]  [A loss: 3.804511, acc: 0.015625]\n",
      "1047: [D loss: 1.340340, acc: 0.544922]  [A loss: 6.559784, acc: 0.000000]\n",
      "1048: [D loss: 0.821704, acc: 0.613281]  [A loss: 0.734787, acc: 0.605469]\n",
      "1049: [D loss: 1.683161, acc: 0.535156]  [A loss: 9.885137, acc: 0.000000]\n",
      "1050: [D loss: 1.346102, acc: 0.562500]  [A loss: 0.005870, acc: 1.000000]\n",
      "1051: [D loss: 4.614882, acc: 0.500000]  [A loss: 3.585448, acc: 0.046875]\n",
      "1052: [D loss: 1.501546, acc: 0.552734]  [A loss: 7.893253, acc: 0.000000]\n",
      "1053: [D loss: 0.993029, acc: 0.587891]  [A loss: 0.240877, acc: 0.890625]\n",
      "1054: [D loss: 2.182309, acc: 0.511719]  [A loss: 7.744501, acc: 0.000000]\n",
      "1055: [D loss: 1.027907, acc: 0.582031]  [A loss: 0.108902, acc: 0.972656]\n",
      "1056: [D loss: 2.545738, acc: 0.513672]  [A loss: 8.346504, acc: 0.000000]\n",
      "1057: [D loss: 0.981578, acc: 0.609375]  [A loss: 0.070879, acc: 0.984375]\n",
      "1058: [D loss: 2.749600, acc: 0.503906]  [A loss: 5.471384, acc: 0.003906]\n",
      "1059: [D loss: 0.921686, acc: 0.628906]  [A loss: 3.557933, acc: 0.042969]\n",
      "1060: [D loss: 1.568231, acc: 0.560547]  [A loss: 9.712962, acc: 0.000000]\n",
      "1061: [D loss: 1.361225, acc: 0.546875]  [A loss: 0.012961, acc: 1.000000]\n",
      "1062: [D loss: 4.000028, acc: 0.500000]  [A loss: 2.513685, acc: 0.117188]\n",
      "1063: [D loss: 1.766472, acc: 0.546875]  [A loss: 8.109407, acc: 0.000000]\n",
      "1064: [D loss: 1.019197, acc: 0.599609]  [A loss: 0.383749, acc: 0.804688]\n",
      "1065: [D loss: 2.097582, acc: 0.521484]  [A loss: 8.643750, acc: 0.000000]\n",
      "1066: [D loss: 1.056039, acc: 0.587891]  [A loss: 0.117310, acc: 0.972656]\n",
      "1067: [D loss: 2.376395, acc: 0.507812]  [A loss: 6.817312, acc: 0.000000]\n",
      "1068: [D loss: 0.876398, acc: 0.625000]  [A loss: 1.064197, acc: 0.414062]\n",
      "1069: [D loss: 1.705208, acc: 0.548828]  [A loss: 7.812431, acc: 0.000000]\n",
      "1070: [D loss: 0.957782, acc: 0.589844]  [A loss: 0.283818, acc: 0.882812]\n",
      "1071: [D loss: 1.488077, acc: 0.546875]  [A loss: 6.741963, acc: 0.000000]\n",
      "1072: [D loss: 0.910059, acc: 0.597656]  [A loss: 0.902308, acc: 0.554688]\n",
      "1073: [D loss: 1.600184, acc: 0.537109]  [A loss: 9.131395, acc: 0.000000]\n",
      "1074: [D loss: 1.190179, acc: 0.572266]  [A loss: 0.015535, acc: 1.000000]\n",
      "1075: [D loss: 3.770271, acc: 0.500000]  [A loss: 4.540256, acc: 0.023438]\n",
      "1076: [D loss: 1.100679, acc: 0.611328]  [A loss: 6.081311, acc: 0.000000]\n",
      "1077: [D loss: 1.084828, acc: 0.576172]  [A loss: 4.816518, acc: 0.000000]\n",
      "1078: [D loss: 1.337433, acc: 0.554688]  [A loss: 9.055145, acc: 0.000000]\n",
      "1079: [D loss: 1.167216, acc: 0.583984]  [A loss: 0.038810, acc: 1.000000]\n",
      "1080: [D loss: 3.293083, acc: 0.503906]  [A loss: 7.365170, acc: 0.000000]\n",
      "1081: [D loss: 0.970567, acc: 0.550781]  [A loss: 0.224500, acc: 0.906250]\n",
      "1082: [D loss: 2.164463, acc: 0.523438]  [A loss: 8.297373, acc: 0.000000]\n",
      "1083: [D loss: 1.295499, acc: 0.535156]  [A loss: 0.031166, acc: 1.000000]\n",
      "1084: [D loss: 3.357826, acc: 0.500000]  [A loss: 4.138445, acc: 0.003906]\n",
      "1085: [D loss: 0.930069, acc: 0.648438]  [A loss: 4.247807, acc: 0.011719]\n",
      "1086: [D loss: 1.121471, acc: 0.593750]  [A loss: 5.209909, acc: 0.003906]\n",
      "1087: [D loss: 0.964938, acc: 0.585938]  [A loss: 2.566086, acc: 0.074219]\n",
      "1088: [D loss: 1.652859, acc: 0.542969]  [A loss: 9.730531, acc: 0.000000]\n",
      "1089: [D loss: 1.903997, acc: 0.494141]  [A loss: 0.007562, acc: 1.000000]\n",
      "1090: [D loss: 4.945065, acc: 0.500000]  [A loss: 1.425824, acc: 0.351562]\n",
      "1091: [D loss: 1.998339, acc: 0.537109]  [A loss: 9.835574, acc: 0.000000]\n",
      "1092: [D loss: 1.526275, acc: 0.535156]  [A loss: 0.020067, acc: 1.000000]\n",
      "1093: [D loss: 3.907344, acc: 0.500000]  [A loss: 2.182626, acc: 0.187500]\n",
      "1094: [D loss: 1.751904, acc: 0.533203]  [A loss: 7.943443, acc: 0.000000]\n",
      "1095: [D loss: 1.149602, acc: 0.539062]  [A loss: 0.248944, acc: 0.878906]\n",
      "1096: [D loss: 2.501278, acc: 0.505859]  [A loss: 7.057436, acc: 0.000000]\n",
      "1097: [D loss: 1.083015, acc: 0.529297]  [A loss: 0.397932, acc: 0.750000]\n",
      "1098: [D loss: 1.766607, acc: 0.523438]  [A loss: 5.899053, acc: 0.000000]\n",
      "1099: [D loss: 0.982474, acc: 0.607422]  [A loss: 1.962850, acc: 0.214844]\n",
      "1100: [D loss: 2.035361, acc: 0.531250]  [A loss: 10.477125, acc: 0.000000]\n",
      "1101: [D loss: 2.013032, acc: 0.501953]  [A loss: 0.008388, acc: 1.000000]\n",
      "1102: [D loss: 4.651445, acc: 0.500000]  [A loss: 1.676569, acc: 0.261719]\n",
      "1103: [D loss: 2.072922, acc: 0.529297]  [A loss: 8.314121, acc: 0.000000]\n",
      "1104: [D loss: 0.925221, acc: 0.609375]  [A loss: 0.414674, acc: 0.781250]\n",
      "1105: [D loss: 1.803573, acc: 0.539062]  [A loss: 7.637461, acc: 0.000000]\n",
      "1106: [D loss: 0.948365, acc: 0.589844]  [A loss: 0.471786, acc: 0.765625]\n",
      "1107: [D loss: 1.756637, acc: 0.539062]  [A loss: 7.182056, acc: 0.000000]\n",
      "1108: [D loss: 1.074561, acc: 0.589844]  [A loss: 0.744303, acc: 0.582031]\n",
      "1109: [D loss: 1.878546, acc: 0.527344]  [A loss: 9.059051, acc: 0.000000]\n",
      "1110: [D loss: 1.100645, acc: 0.554688]  [A loss: 0.112151, acc: 0.964844]\n",
      "1111: [D loss: 2.347934, acc: 0.507812]  [A loss: 7.529223, acc: 0.000000]\n",
      "1112: [D loss: 0.943928, acc: 0.599609]  [A loss: 0.154189, acc: 0.960938]\n",
      "1113: [D loss: 2.109752, acc: 0.519531]  [A loss: 6.523553, acc: 0.000000]\n",
      "1114: [D loss: 0.908183, acc: 0.572266]  [A loss: 0.512862, acc: 0.699219]\n",
      "1115: [D loss: 1.521009, acc: 0.554688]  [A loss: 6.379760, acc: 0.000000]\n",
      "1116: [D loss: 0.792811, acc: 0.630859]  [A loss: 0.655869, acc: 0.648438]\n",
      "1117: [D loss: 1.640684, acc: 0.541016]  [A loss: 7.656637, acc: 0.000000]\n",
      "1118: [D loss: 0.994621, acc: 0.603516]  [A loss: 0.128577, acc: 0.960938]\n",
      "1119: [D loss: 2.612141, acc: 0.507812]  [A loss: 7.818480, acc: 0.000000]\n",
      "1120: [D loss: 1.009005, acc: 0.580078]  [A loss: 0.045548, acc: 1.000000]\n",
      "1121: [D loss: 2.704815, acc: 0.501953]  [A loss: 5.543996, acc: 0.000000]\n",
      "1122: [D loss: 0.976997, acc: 0.583984]  [A loss: 2.592398, acc: 0.078125]\n",
      "1123: [D loss: 1.533090, acc: 0.541016]  [A loss: 8.752684, acc: 0.000000]\n",
      "1124: [D loss: 1.143908, acc: 0.529297]  [A loss: 0.117843, acc: 0.960938]\n",
      "1125: [D loss: 2.338901, acc: 0.511719]  [A loss: 9.931318, acc: 0.000000]\n",
      "1126: [D loss: 1.231842, acc: 0.574219]  [A loss: 0.013380, acc: 1.000000]\n",
      "1127: [D loss: 4.013240, acc: 0.500000]  [A loss: 6.031494, acc: 0.000000]\n",
      "1128: [D loss: 1.084692, acc: 0.617188]  [A loss: 3.890812, acc: 0.015625]\n",
      "1129: [D loss: 1.544164, acc: 0.544922]  [A loss: 8.926600, acc: 0.000000]\n",
      "1130: [D loss: 1.098738, acc: 0.591797]  [A loss: 0.045039, acc: 0.996094]\n",
      "1131: [D loss: 3.226520, acc: 0.505859]  [A loss: 7.297175, acc: 0.000000]\n",
      "1132: [D loss: 1.084023, acc: 0.607422]  [A loss: 2.991911, acc: 0.070312]\n",
      "1133: [D loss: 2.171296, acc: 0.529297]  [A loss: 13.497107, acc: 0.000000]\n",
      "1134: [D loss: 4.196872, acc: 0.498047]  [A loss: 0.004974, acc: 1.000000]\n",
      "1135: [D loss: 5.489910, acc: 0.500000]  [A loss: 0.803623, acc: 0.617188]\n",
      "1136: [D loss: 2.253908, acc: 0.535156]  [A loss: 8.809096, acc: 0.000000]\n",
      "1137: [D loss: 1.174824, acc: 0.544922]  [A loss: 0.703143, acc: 0.613281]\n",
      "1138: [D loss: 1.992043, acc: 0.533203]  [A loss: 8.784542, acc: 0.000000]\n",
      "1139: [D loss: 1.065846, acc: 0.576172]  [A loss: 0.526290, acc: 0.718750]\n",
      "1140: [D loss: 2.249319, acc: 0.521484]  [A loss: 10.456134, acc: 0.000000]\n",
      "1141: [D loss: 1.590369, acc: 0.564453]  [A loss: 0.020730, acc: 0.996094]\n",
      "1142: [D loss: 4.516589, acc: 0.500000]  [A loss: 3.491652, acc: 0.031250]\n",
      "1143: [D loss: 1.794632, acc: 0.539062]  [A loss: 8.103786, acc: 0.000000]\n",
      "1144: [D loss: 1.110614, acc: 0.550781]  [A loss: 1.358542, acc: 0.371094]\n",
      "1145: [D loss: 2.174403, acc: 0.515625]  [A loss: 9.613307, acc: 0.000000]\n",
      "1146: [D loss: 1.223986, acc: 0.539062]  [A loss: 0.104219, acc: 0.972656]\n",
      "1147: [D loss: 2.662187, acc: 0.501953]  [A loss: 7.557321, acc: 0.000000]\n",
      "1148: [D loss: 1.050510, acc: 0.570312]  [A loss: 0.462232, acc: 0.722656]\n",
      "1149: [D loss: 1.844229, acc: 0.517578]  [A loss: 7.882246, acc: 0.000000]\n",
      "1150: [D loss: 1.044261, acc: 0.574219]  [A loss: 0.210902, acc: 0.914062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1151: [D loss: 2.233718, acc: 0.511719]  [A loss: 7.757558, acc: 0.000000]\n",
      "1152: [D loss: 1.016592, acc: 0.593750]  [A loss: 0.125542, acc: 0.953125]\n",
      "1153: [D loss: 2.273234, acc: 0.511719]  [A loss: 6.127300, acc: 0.000000]\n",
      "1154: [D loss: 0.928764, acc: 0.621094]  [A loss: 2.802919, acc: 0.121094]\n",
      "1155: [D loss: 1.625575, acc: 0.541016]  [A loss: 8.014194, acc: 0.000000]\n",
      "1156: [D loss: 0.972985, acc: 0.580078]  [A loss: 0.281992, acc: 0.875000]\n",
      "1157: [D loss: 2.105134, acc: 0.529297]  [A loss: 9.997329, acc: 0.000000]\n",
      "1158: [D loss: 1.511948, acc: 0.554688]  [A loss: 0.003556, acc: 1.000000]\n",
      "1159: [D loss: 5.109355, acc: 0.500000]  [A loss: 3.291367, acc: 0.070312]\n",
      "1160: [D loss: 1.825828, acc: 0.513672]  [A loss: 9.127437, acc: 0.000000]\n",
      "1161: [D loss: 1.145949, acc: 0.564453]  [A loss: 0.148093, acc: 0.929688]\n",
      "1162: [D loss: 2.543301, acc: 0.503906]  [A loss: 8.292441, acc: 0.000000]\n",
      "1163: [D loss: 1.059429, acc: 0.587891]  [A loss: 0.599464, acc: 0.664062]\n",
      "1164: [D loss: 1.991670, acc: 0.525391]  [A loss: 8.800337, acc: 0.000000]\n",
      "1165: [D loss: 1.205394, acc: 0.546875]  [A loss: 0.045920, acc: 0.996094]\n",
      "1166: [D loss: 3.480610, acc: 0.500000]  [A loss: 5.496692, acc: 0.000000]\n",
      "1167: [D loss: 1.059608, acc: 0.576172]  [A loss: 4.256401, acc: 0.023438]\n",
      "1168: [D loss: 1.157488, acc: 0.589844]  [A loss: 7.215228, acc: 0.000000]\n",
      "1169: [D loss: 0.930981, acc: 0.613281]  [A loss: 0.535071, acc: 0.730469]\n",
      "1170: [D loss: 1.831586, acc: 0.541016]  [A loss: 8.840753, acc: 0.000000]\n",
      "1171: [D loss: 1.146176, acc: 0.574219]  [A loss: 0.052945, acc: 0.992188]\n",
      "1172: [D loss: 3.245109, acc: 0.501953]  [A loss: 7.031672, acc: 0.000000]\n",
      "1173: [D loss: 0.889000, acc: 0.636719]  [A loss: 2.173516, acc: 0.199219]\n",
      "1174: [D loss: 1.868202, acc: 0.519531]  [A loss: 10.232733, acc: 0.000000]\n",
      "1175: [D loss: 1.489277, acc: 0.544922]  [A loss: 0.008244, acc: 1.000000]\n",
      "1176: [D loss: 4.639286, acc: 0.500000]  [A loss: 2.719228, acc: 0.097656]\n",
      "1177: [D loss: 1.706456, acc: 0.558594]  [A loss: 9.272438, acc: 0.000000]\n",
      "1178: [D loss: 1.237681, acc: 0.541016]  [A loss: 0.247094, acc: 0.882812]\n",
      "1179: [D loss: 2.387754, acc: 0.515625]  [A loss: 8.864107, acc: 0.000000]\n",
      "1180: [D loss: 1.170135, acc: 0.625000]  [A loss: 0.072188, acc: 0.980469]\n",
      "1181: [D loss: 3.110356, acc: 0.501953]  [A loss: 5.993433, acc: 0.003906]\n",
      "1182: [D loss: 1.015586, acc: 0.615234]  [A loss: 4.158382, acc: 0.011719]\n",
      "1183: [D loss: 1.675273, acc: 0.556641]  [A loss: 10.335390, acc: 0.000000]\n",
      "1184: [D loss: 1.423586, acc: 0.539062]  [A loss: 0.022272, acc: 1.000000]\n",
      "1185: [D loss: 4.534618, acc: 0.501953]  [A loss: 3.981620, acc: 0.054688]\n",
      "1186: [D loss: 2.302032, acc: 0.542969]  [A loss: 12.901445, acc: 0.000000]\n",
      "1187: [D loss: 3.073361, acc: 0.500000]  [A loss: 0.001168, acc: 1.000000]\n",
      "1188: [D loss: 6.690811, acc: 0.500000]  [A loss: 0.062369, acc: 0.968750]\n",
      "1189: [D loss: 4.579362, acc: 0.503906]  [A loss: 6.746487, acc: 0.027344]\n",
      "1190: [D loss: 2.494388, acc: 0.542969]  [A loss: 13.746829, acc: 0.000000]\n",
      "1191: [D loss: 3.444706, acc: 0.511719]  [A loss: 0.001382, acc: 1.000000]\n",
      "1192: [D loss: 6.651712, acc: 0.500000]  [A loss: 0.060068, acc: 0.976562]\n",
      "1193: [D loss: 4.599598, acc: 0.500000]  [A loss: 7.681658, acc: 0.007812]\n",
      "1194: [D loss: 3.540689, acc: 0.515625]  [A loss: 12.533482, acc: 0.000000]\n",
      "1195: [D loss: 2.447787, acc: 0.507812]  [A loss: 0.030399, acc: 0.992188]\n",
      "1196: [D loss: 5.286210, acc: 0.505859]  [A loss: 3.918529, acc: 0.128906]\n",
      "1197: [D loss: 4.484586, acc: 0.505859]  [A loss: 10.864595, acc: 0.000000]\n",
      "1198: [D loss: 1.638581, acc: 0.603516]  [A loss: 3.209639, acc: 0.199219]\n",
      "1199: [D loss: 4.474153, acc: 0.505859]  [A loss: 12.143843, acc: 0.003906]\n",
      "1200: [D loss: 2.477753, acc: 0.496094]  [A loss: 0.047422, acc: 0.984375]\n",
      "1201: [D loss: 5.350996, acc: 0.505859]  [A loss: 3.060831, acc: 0.253906]\n",
      "1202: [D loss: 3.856880, acc: 0.533203]  [A loss: 12.270968, acc: 0.000000]\n",
      "1203: [D loss: 2.404068, acc: 0.515625]  [A loss: 0.029768, acc: 0.984375]\n",
      "1204: [D loss: 5.700533, acc: 0.500000]  [A loss: 1.206346, acc: 0.566406]\n",
      "1205: [D loss: 3.584069, acc: 0.505859]  [A loss: 12.725643, acc: 0.000000]\n",
      "1206: [D loss: 2.112207, acc: 0.548828]  [A loss: 0.043213, acc: 0.988281]\n",
      "1207: [D loss: 4.837396, acc: 0.503906]  [A loss: 5.460565, acc: 0.101562]\n",
      "1208: [D loss: 4.711486, acc: 0.515625]  [A loss: 9.971129, acc: 0.000000]\n",
      "1209: [D loss: 2.697059, acc: 0.529297]  [A loss: 12.250461, acc: 0.000000]\n",
      "1210: [D loss: 2.402435, acc: 0.484375]  [A loss: 0.197558, acc: 0.890625]\n",
      "1211: [D loss: 4.509764, acc: 0.513672]  [A loss: 8.167418, acc: 0.027344]\n",
      "1212: [D loss: 3.292613, acc: 0.539062]  [A loss: 13.629886, acc: 0.000000]\n",
      "1213: [D loss: 5.613575, acc: 0.498047]  [A loss: 0.046502, acc: 0.988281]\n",
      "1214: [D loss: 5.083035, acc: 0.505859]  [A loss: 0.925808, acc: 0.613281]\n",
      "1215: [D loss: 3.448834, acc: 0.548828]  [A loss: 11.661612, acc: 0.003906]\n",
      "1216: [D loss: 2.115958, acc: 0.503906]  [A loss: 0.134503, acc: 0.933594]\n",
      "1217: [D loss: 4.447647, acc: 0.525391]  [A loss: 4.455495, acc: 0.109375]\n",
      "1218: [D loss: 4.232824, acc: 0.525391]  [A loss: 10.091911, acc: 0.000000]\n",
      "1219: [D loss: 2.232441, acc: 0.500000]  [A loss: 6.240467, acc: 0.054688]\n",
      "1220: [D loss: 4.111752, acc: 0.517578]  [A loss: 12.757511, acc: 0.000000]\n",
      "1221: [D loss: 4.662690, acc: 0.498047]  [A loss: 0.065069, acc: 0.984375]\n",
      "1222: [D loss: 5.513192, acc: 0.505859]  [A loss: 0.559059, acc: 0.742188]\n",
      "1223: [D loss: 4.305976, acc: 0.525391]  [A loss: 8.369876, acc: 0.011719]\n",
      "1224: [D loss: 2.108385, acc: 0.558594]  [A loss: 9.549371, acc: 0.011719]\n",
      "1225: [D loss: 1.746274, acc: 0.558594]  [A loss: 2.745035, acc: 0.207031]\n",
      "1226: [D loss: 3.256371, acc: 0.560547]  [A loss: 11.052166, acc: 0.000000]\n",
      "1227: [D loss: 2.643140, acc: 0.507812]  [A loss: 0.069616, acc: 0.976562]\n",
      "1228: [D loss: 5.374054, acc: 0.503906]  [A loss: 0.616425, acc: 0.699219]\n",
      "1229: [D loss: 3.108042, acc: 0.542969]  [A loss: 11.512766, acc: 0.000000]\n",
      "1230: [D loss: 2.958199, acc: 0.519531]  [A loss: 0.042007, acc: 0.984375]\n",
      "1231: [D loss: 5.076660, acc: 0.503906]  [A loss: 0.500934, acc: 0.742188]\n",
      "1232: [D loss: 3.137610, acc: 0.568359]  [A loss: 7.843305, acc: 0.023438]\n",
      "1233: [D loss: 2.704543, acc: 0.585938]  [A loss: 11.274153, acc: 0.003906]\n",
      "1234: [D loss: 2.119634, acc: 0.558594]  [A loss: 0.149673, acc: 0.933594]\n",
      "1235: [D loss: 3.754117, acc: 0.525391]  [A loss: 6.875402, acc: 0.011719]\n",
      "1236: [D loss: 3.027030, acc: 0.560547]  [A loss: 10.406804, acc: 0.003906]\n",
      "1237: [D loss: 2.048703, acc: 0.537109]  [A loss: 0.329538, acc: 0.796875]\n",
      "1238: [D loss: 3.866844, acc: 0.544922]  [A loss: 9.223146, acc: 0.007812]\n",
      "1239: [D loss: 2.528841, acc: 0.566406]  [A loss: 11.376785, acc: 0.000000]\n",
      "1240: [D loss: 2.682054, acc: 0.531250]  [A loss: 0.034472, acc: 0.992188]\n",
      "1241: [D loss: 5.616124, acc: 0.500000]  [A loss: 0.211895, acc: 0.898438]\n",
      "1242: [D loss: 4.081735, acc: 0.533203]  [A loss: 9.218349, acc: 0.003906]\n",
      "1243: [D loss: 2.769210, acc: 0.560547]  [A loss: 12.505556, acc: 0.000000]\n",
      "1244: [D loss: 3.959682, acc: 0.513672]  [A loss: 0.019375, acc: 1.000000]\n",
      "1245: [D loss: 6.246682, acc: 0.500000]  [A loss: 0.078857, acc: 0.968750]\n",
      "1246: [D loss: 5.512359, acc: 0.501953]  [A loss: 1.521836, acc: 0.542969]\n",
      "1247: [D loss: 4.984082, acc: 0.527344]  [A loss: 8.016219, acc: 0.046875]\n",
      "1248: [D loss: 4.967253, acc: 0.517578]  [A loss: 11.827284, acc: 0.003906]\n",
      "1249: [D loss: 2.628163, acc: 0.533203]  [A loss: 1.987034, acc: 0.429688]\n",
      "1250: [D loss: 5.195970, acc: 0.513672]  [A loss: 10.221340, acc: 0.003906]\n",
      "1251: [D loss: 3.146332, acc: 0.541016]  [A loss: 13.219835, acc: 0.000000]\n",
      "1252: [D loss: 5.875981, acc: 0.509766]  [A loss: 0.034500, acc: 0.992188]\n",
      "1253: [D loss: 6.229191, acc: 0.507812]  [A loss: 0.171762, acc: 0.906250]\n",
      "1254: [D loss: 5.237125, acc: 0.517578]  [A loss: 6.549683, acc: 0.097656]\n",
      "1255: [D loss: 5.620367, acc: 0.519531]  [A loss: 3.502031, acc: 0.324219]\n",
      "1256: [D loss: 6.578271, acc: 0.515625]  [A loss: 4.115880, acc: 0.242188]\n",
      "1257: [D loss: 6.606226, acc: 0.507812]  [A loss: 5.138226, acc: 0.207031]\n",
      "1258: [D loss: 6.692113, acc: 0.509766]  [A loss: 8.067324, acc: 0.117188]\n",
      "1259: [D loss: 7.086218, acc: 0.500000]  [A loss: 5.962833, acc: 0.250000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1260: [D loss: 7.237757, acc: 0.501953]  [A loss: 3.361272, acc: 0.429688]\n",
      "1261: [D loss: 7.086642, acc: 0.501953]  [A loss: 4.044038, acc: 0.390625]\n",
      "1262: [D loss: 7.249311, acc: 0.500000]  [A loss: 2.921367, acc: 0.539062]\n",
      "1263: [D loss: 7.232054, acc: 0.494141]  [A loss: 10.151714, acc: 0.074219]\n",
      "1264: [D loss: 6.763124, acc: 0.486328]  [A loss: 16.091528, acc: 0.000000]\n",
      "1265: [D loss: 8.059052, acc: 0.500000]  [A loss: 16.106422, acc: 0.000000]\n",
      "1266: [D loss: 8.050802, acc: 0.500000]  [A loss: 16.083206, acc: 0.000000]\n",
      "1267: [D loss: 8.049097, acc: 0.500000]  [A loss: 16.059258, acc: 0.000000]\n",
      "1268: [D loss: 8.047041, acc: 0.500000]  [A loss: 16.047302, acc: 0.000000]\n",
      "1269: [D loss: 8.031905, acc: 0.500000]  [A loss: 15.969795, acc: 0.000000]\n",
      "1270: [D loss: 8.029876, acc: 0.500000]  [A loss: 15.225248, acc: 0.011719]\n",
      "1271: [D loss: 6.253259, acc: 0.515625]  [A loss: 0.000006, acc: 1.000000]\n",
      "1272: [D loss: 7.938692, acc: 0.500000]  [A loss: 0.000001, acc: 1.000000]\n",
      "1273: [D loss: 7.918792, acc: 0.500000]  [A loss: 0.000001, acc: 1.000000]\n",
      "1274: [D loss: 7.900290, acc: 0.500000]  [A loss: 0.000021, acc: 1.000000]\n",
      "1275: [D loss: 7.892984, acc: 0.500000]  [A loss: 0.000069, acc: 1.000000]\n",
      "1276: [D loss: 7.848744, acc: 0.500000]  [A loss: 0.000726, acc: 1.000000]\n",
      "1277: [D loss: 7.794400, acc: 0.501953]  [A loss: 0.010119, acc: 0.996094]\n",
      "1278: [D loss: 7.636241, acc: 0.500000]  [A loss: 0.302555, acc: 0.914062]\n",
      "1279: [D loss: 7.343281, acc: 0.505859]  [A loss: 10.696520, acc: 0.136719]\n",
      "1280: [D loss: 7.687996, acc: 0.503906]  [A loss: 0.819620, acc: 0.855469]\n",
      "1281: [D loss: 7.700099, acc: 0.496094]  [A loss: 1.488047, acc: 0.796875]\n",
      "1282: [D loss: 7.698179, acc: 0.498047]  [A loss: 2.299039, acc: 0.671875]\n",
      "1283: [D loss: 7.916613, acc: 0.498047]  [A loss: 0.044069, acc: 0.996094]\n",
      "1284: [D loss: 7.899233, acc: 0.492188]  [A loss: 0.072259, acc: 0.976562]\n",
      "1285: [D loss: 7.688223, acc: 0.490234]  [A loss: 10.835860, acc: 0.191406]\n",
      "1286: [D loss: 7.779330, acc: 0.492188]  [A loss: 2.907219, acc: 0.687500]\n",
      "1287: [D loss: 7.906501, acc: 0.500000]  [A loss: 0.316640, acc: 0.960938]\n",
      "1288: [D loss: 7.693375, acc: 0.492188]  [A loss: 5.685008, acc: 0.500000]\n",
      "1289: [D loss: 8.020779, acc: 0.490234]  [A loss: 0.003512, acc: 0.996094]\n",
      "1290: [D loss: 7.995769, acc: 0.486328]  [A loss: 0.281762, acc: 0.964844]\n",
      "1291: [D loss: 7.974637, acc: 0.488281]  [A loss: 2.180732, acc: 0.796875]\n",
      "1292: [D loss: 7.929235, acc: 0.501953]  [A loss: 0.102583, acc: 0.988281]\n",
      "1293: [D loss: 7.944926, acc: 0.500000]  [A loss: 1.031339, acc: 0.894531]\n",
      "1294: [D loss: 7.833852, acc: 0.496094]  [A loss: 5.490697, acc: 0.562500]\n",
      "1295: [D loss: 7.971224, acc: 0.500000]  [A loss: 0.000009, acc: 1.000000]\n",
      "1296: [D loss: 7.971873, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1297: [D loss: 7.971198, acc: 0.500000]  [A loss: 0.000001, acc: 1.000000]\n",
      "1298: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1299: [D loss: 7.951774, acc: 0.500000]  [A loss: 0.000044, acc: 1.000000]\n",
      "1300: [D loss: 7.964183, acc: 0.486328]  [A loss: 8.478501, acc: 0.359375]\n",
      "1301: [D loss: 7.961446, acc: 0.500000]  [A loss: 0.025171, acc: 0.996094]\n",
      "1302: [D loss: 7.947090, acc: 0.498047]  [A loss: 3.166736, acc: 0.738281]\n",
      "1303: [D loss: 8.002675, acc: 0.498047]  [A loss: 0.000485, acc: 1.000000]\n",
      "1304: [D loss: 7.948450, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1305: [D loss: 7.941975, acc: 0.500000]  [A loss: 0.062967, acc: 0.996094]\n",
      "1306: [D loss: 7.996734, acc: 0.494141]  [A loss: 0.000000, acc: 1.000000]\n",
      "1307: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1308: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1309: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1310: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1311: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1312: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1313: [D loss: 7.972151, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1314: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1315: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1316: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1317: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1318: [D loss: 7.964485, acc: 0.500000]  [A loss: 0.042542, acc: 0.996094]\n",
      "1319: [D loss: 7.971201, acc: 0.500000]  [A loss: 0.149892, acc: 0.988281]\n",
      "1320: [D loss: 7.977206, acc: 0.498047]  [A loss: 0.062961, acc: 0.996094]\n",
      "1321: [D loss: 7.938646, acc: 0.500000]  [A loss: 7.217147, acc: 0.468750]\n",
      "1322: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1323: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1324: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1325: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1326: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1327: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1328: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1329: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1330: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1331: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1332: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1333: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1334: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1335: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1336: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1337: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1338: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1339: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1340: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1341: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1342: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1343: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1344: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1345: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1346: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1347: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1348: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1349: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1350: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1351: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1352: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1353: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1354: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1355: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "1356: [D loss: 7.971192, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "DCGAN on MNIST using Keras\n",
    "Author: Rowel Atienza\n",
    "Project: https://github.com/roatienza/Deep-Learning-Experiments\n",
    "Dependencies: tensorflow 1.0 and keras 2.0\n",
    "Usage: python3 dcgan_mnist.py\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ElapsedTimer(object):\n",
    "    def __init__(self):\n",
    "        self.start_time = time.time()\n",
    "    def elapsed(self,sec):\n",
    "        if sec < 60:\n",
    "            return str(sec) + \" sec\"\n",
    "        elif sec < (60 * 60):\n",
    "            return str(sec / 60) + \" min\"\n",
    "        else:\n",
    "            return str(sec / (60 * 60)) + \" hr\"\n",
    "    def elapsed_time(self):\n",
    "        print(\"Elapsed: %s \" % self.elapsed(time.time() - self.start_time) )\n",
    "\n",
    "class DCGAN(object):\n",
    "    def __init__(self, img_rows=28, img_cols=28, channel=1):\n",
    "\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.channel = channel\n",
    "        self.D = None   # discriminator\n",
    "        self.G = None   # generator\n",
    "        self.AM = None  # adversarial model\n",
    "        self.DM = None  # discriminator model\n",
    "\n",
    "    # (W−F+2P)/S+1\n",
    "    def discriminator(self):\n",
    "        if self.D:\n",
    "            return self.D\n",
    "        self.D = Sequential()\n",
    "        depth = 64\n",
    "        dropout = 0.4\n",
    "        # In: 28 x 28 x 1, depth = 1\n",
    "        # Out: 14 x 14 x 1, depth=64\n",
    "        input_shape = (self.img_rows, self.img_cols, self.channel)\n",
    "        self.D.add(Conv2D(depth*1, 5, strides=2, input_shape=input_shape,\\\n",
    "            padding='same'))\n",
    "        self.D.add(LeakyReLU(alpha=0.2))\n",
    "        self.D.add(Dropout(dropout))\n",
    "\n",
    "        self.D.add(Conv2D(depth*2, 5, strides=2, padding='same'))\n",
    "        self.D.add(LeakyReLU(alpha=0.2))\n",
    "        self.D.add(Dropout(dropout))\n",
    "\n",
    "        self.D.add(Conv2D(depth*4, 5, strides=2, padding='same'))\n",
    "        self.D.add(LeakyReLU(alpha=0.2))\n",
    "        self.D.add(Dropout(dropout))\n",
    "\n",
    "        self.D.add(Conv2D(depth*8, 5, strides=1, padding='same'))\n",
    "        self.D.add(LeakyReLU(alpha=0.2))\n",
    "        self.D.add(Dropout(dropout))\n",
    "\n",
    "        # Out: 1-dim probability\n",
    "        self.D.add(Flatten())\n",
    "        self.D.add(Dense(1))\n",
    "        self.D.add(Activation('sigmoid'))\n",
    "        self.D.summary()\n",
    "        return self.D\n",
    "\n",
    "    def generator(self):\n",
    "        if self.G:\n",
    "            return self.G\n",
    "        self.G = Sequential()\n",
    "        dropout = 0.4\n",
    "        depth = 64+64+64+64\n",
    "        dim = 7\n",
    "        # In: 100\n",
    "        # Out: dim x dim x depth\n",
    "        self.G.add(Dense(dim*dim*depth, input_dim=100))\n",
    "        self.G.add(BatchNormalization(momentum=0.9))\n",
    "        self.G.add(Activation('relu'))\n",
    "        self.G.add(Reshape((dim, dim, depth)))\n",
    "        self.G.add(Dropout(dropout))\n",
    "\n",
    "        # In: dim x dim x depth\n",
    "        # Out: 2*dim x 2*dim x depth/2\n",
    "        self.G.add(UpSampling2D())\n",
    "        self.G.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\n",
    "        self.G.add(BatchNormalization(momentum=0.9))\n",
    "        self.G.add(Activation('relu'))\n",
    "\n",
    "        self.G.add(UpSampling2D())\n",
    "        self.G.add(Conv2DTranspose(int(depth/4), 5, padding='same'))\n",
    "        self.G.add(BatchNormalization(momentum=0.9))\n",
    "        self.G.add(Activation('relu'))\n",
    "\n",
    "        self.G.add(Conv2DTranspose(int(depth/8), 5, padding='same'))\n",
    "        self.G.add(BatchNormalization(momentum=0.9))\n",
    "        self.G.add(Activation('relu'))\n",
    "\n",
    "        # Out: 28 x 28 x 1 grayscale image [0.0,1.0] per pix\n",
    "        self.G.add(Conv2DTranspose(1, 5, padding='same'))\n",
    "        self.G.add(Activation('sigmoid'))\n",
    "        self.G.summary()\n",
    "        return self.G\n",
    "\n",
    "    def discriminator_model(self):\n",
    "        if self.DM:\n",
    "            return self.DM\n",
    "        optimizer = RMSprop(lr=0.0002, decay=6e-8)\n",
    "        self.DM = Sequential()\n",
    "        self.DM.add(self.discriminator())\n",
    "        self.DM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
    "            metrics=['accuracy'])\n",
    "        return self.DM\n",
    "\n",
    "    def adversarial_model(self):\n",
    "        if self.AM:\n",
    "            return self.AM\n",
    "        optimizer = RMSprop(lr=0.0001, decay=3e-8)\n",
    "        self.AM = Sequential()\n",
    "        self.AM.add(self.generator())\n",
    "        self.AM.add(self.discriminator())\n",
    "        self.AM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
    "            metrics=['accuracy'])\n",
    "        return self.AM\n",
    "\n",
    "class MNIST_DCGAN(object):\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channel = 1\n",
    "\n",
    "        self.x_train = input_data.read_data_sets(\"mnist\",\\\n",
    "        \tone_hot=True).train.images\n",
    "        self.x_train = self.x_train.reshape(-1, self.img_rows,\\\n",
    "        \tself.img_cols, 1).astype(np.float32)\n",
    "\n",
    "        self.DCGAN = DCGAN()\n",
    "        self.discriminator =  self.DCGAN.discriminator_model()\n",
    "        self.adversarial = self.DCGAN.adversarial_model()\n",
    "        self.generator = self.DCGAN.generator()\n",
    "\n",
    "    def train(self, train_steps=2000, batch_size=256, save_interval=0):\n",
    "        noise_input = None\n",
    "        if save_interval>0:\n",
    "            noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
    "        for i in range(train_steps):\n",
    "            images_train = self.x_train[np.random.randint(0,\n",
    "                self.x_train.shape[0], size=batch_size), :, :, :]\n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
    "            images_fake = self.generator.predict(noise)\n",
    "            x = np.concatenate((images_train, images_fake))\n",
    "            y = np.ones([2*batch_size, 1])\n",
    "            y[batch_size:, :] = 0\n",
    "            d_loss = self.discriminator.train_on_batch(x, y)\n",
    "\n",
    "            y = np.ones([batch_size, 1])\n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
    "            a_loss = self.adversarial.train_on_batch(noise, y)\n",
    "            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n",
    "            log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n",
    "            print(log_mesg)\n",
    "            if save_interval>0:\n",
    "                if (i+1)%save_interval==0:\n",
    "                    self.plot_images(save2file=True, samples=noise_input.shape[0],\\\n",
    "                        noise=noise_input, step=(i+1))\n",
    "\n",
    "    def plot_images(self, save2file=False, fake=True, samples=16, noise=None, step=0):\n",
    "        filename = 'mnist.png'\n",
    "        if fake:\n",
    "            if noise is None:\n",
    "                noise = np.random.uniform(-1.0, 1.0, size=[samples, 100])\n",
    "            else:\n",
    "                filename = \"mnist_%d.png\" % step\n",
    "            images = self.generator.predict(noise)\n",
    "        else:\n",
    "            i = np.random.randint(0, self.x_train.shape[0], samples)\n",
    "            images = self.x_train[i, :, :, :]\n",
    "\n",
    "        plt.figure(figsize=(10,10))\n",
    "        for i in range(images.shape[0]):\n",
    "            plt.subplot(4, 4, i+1)\n",
    "            image = images[i, :, :, :]\n",
    "            image = np.reshape(image, [self.img_rows, self.img_cols])\n",
    "            plt.imshow(image, cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        if save2file:\n",
    "            plt.savefig(filename)\n",
    "            plt.close('all')\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mnist_dcgan = MNIST_DCGAN()\n",
    "    timer = ElapsedTimer()\n",
    "    mnist_dcgan.train(train_steps=10000, batch_size=256, save_interval=500)\n",
    "    timer.elapsed_time()\n",
    "    mnist_dcgan.plot_images(fake=True)\n",
    "    mnist_dcgan.plot_images(fake=False, save2file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
